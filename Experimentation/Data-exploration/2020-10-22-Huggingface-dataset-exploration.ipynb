{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from datasets import list_datasets, list_metrics, load_dataset, load_metric\n",
    "from pprint import pprint\n",
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aeslc',\n",
       " 'ag_news',\n",
       " 'ai2_arc',\n",
       " 'allocine',\n",
       " 'anli',\n",
       " 'arcd',\n",
       " 'art',\n",
       " 'billsum',\n",
       " 'biomrc',\n",
       " 'blended_skill_talk',\n",
       " 'blimp',\n",
       " 'blog_authorship_corpus',\n",
       " 'bookcorpus',\n",
       " 'boolq',\n",
       " 'break_data',\n",
       " 'c4',\n",
       " 'cfq',\n",
       " 'civil_comments',\n",
       " 'clue',\n",
       " 'cmrc2018',\n",
       " 'cnn_dailymail',\n",
       " 'coarse_discourse',\n",
       " 'com_qa',\n",
       " 'common_gen',\n",
       " 'commonsense_qa',\n",
       " 'compguesswhat',\n",
       " 'conll2000',\n",
       " 'conll2003',\n",
       " 'coqa',\n",
       " 'cornell_movie_dialog',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'crd3',\n",
       " 'crime_and_punish',\n",
       " 'csv',\n",
       " 'daily_dialog',\n",
       " 'definite_pronoun_resolution',\n",
       " 'discofuse',\n",
       " 'docred',\n",
       " 'doqa',\n",
       " 'drop',\n",
       " 'eli5',\n",
       " 'emo',\n",
       " 'emotion',\n",
       " 'empathetic_dialogues',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'event2Mind',\n",
       " 'fever',\n",
       " 'flores',\n",
       " 'fquad',\n",
       " 'gap',\n",
       " 'germeval_14',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'guardian_authorship',\n",
       " 'hans',\n",
       " 'hansards',\n",
       " 'hellaswag',\n",
       " 'hotpot_qa',\n",
       " 'hyperpartisan_news_detection',\n",
       " 'imdb',\n",
       " 'iwslt2017',\n",
       " 'jeopardy',\n",
       " 'json',\n",
       " 'kilt_tasks',\n",
       " 'kilt_wikipedia',\n",
       " 'kor_nli',\n",
       " 'lc_quad',\n",
       " 'lhoestq/squad',\n",
       " 'librispeech_lm',\n",
       " 'lince',\n",
       " 'lm1b',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'matinf',\n",
       " 'mlqa',\n",
       " 'mlsum',\n",
       " 'movie_rationales',\n",
       " 'ms_marco',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'mwsc',\n",
       " 'natural_questions',\n",
       " 'newsgroup',\n",
       " 'newsroom',\n",
       " 'openbookqa',\n",
       " 'openwebtext',\n",
       " 'opinosis',\n",
       " 'pandas',\n",
       " 'para_crawl',\n",
       " 'pg19',\n",
       " 'piaf',\n",
       " 'polyglot_ner',\n",
       " 'qa4mre',\n",
       " 'qa_zre',\n",
       " 'qangaroo',\n",
       " 'qanta',\n",
       " 'qasc',\n",
       " 'quail',\n",
       " 'quarel',\n",
       " 'quartz',\n",
       " 'quora',\n",
       " 'quoref',\n",
       " 'race',\n",
       " 'reclor',\n",
       " 'reddit',\n",
       " 'reddit_tifu',\n",
       " 'reuters21578',\n",
       " 'rotten_tomatoes',\n",
       " 'scan',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scifact',\n",
       " 'sciq',\n",
       " 'scitail',\n",
       " 'search_qa',\n",
       " 'sentiment140',\n",
       " 'snli',\n",
       " 'social_bias_frames',\n",
       " 'social_i_qa',\n",
       " 'sogou_news',\n",
       " 'squad',\n",
       " 'squad_es',\n",
       " 'squad_it',\n",
       " 'squad_v1_pt',\n",
       " 'squad_v2',\n",
       " 'squadshifts',\n",
       " 'sshleifer/pseudo_bart_xsum',\n",
       " 'style_change_detection',\n",
       " 'super_glue',\n",
       " 'ted_hrlr',\n",
       " 'ted_multi',\n",
       " 'text',\n",
       " 'tiny_shakespeare',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydiqa',\n",
       " 'ubuntu_dialogs_corpus',\n",
       " 'web_of_science',\n",
       " 'web_questions',\n",
       " 'wiki40b',\n",
       " 'wiki_dpr',\n",
       " 'wiki_qa',\n",
       " 'wiki_snippets',\n",
       " 'wiki_split',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikisql',\n",
       " 'wikitext',\n",
       " 'winogrande',\n",
       " 'wiqa',\n",
       " 'wmt14',\n",
       " 'wmt15',\n",
       " 'wmt16',\n",
       " 'wmt17',\n",
       " 'wmt18',\n",
       " 'wmt19',\n",
       " 'wmt_t2t',\n",
       " 'wnut_17',\n",
       " 'x_stance',\n",
       " 'xcopa',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme',\n",
       " 'yelp_polarity']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = list_datasets()\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some that seem interesting to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET\t|\t AG_NEWS\n",
      "{'author': None,\n",
      " 'citation': '@inproceedings{Zhang2015CharacterlevelCN,\\n'\n",
      "             '  title={Character-level Convolutional Networks for Text '\n",
      "             'Classification},\\n'\n",
      "             '  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},\\n'\n",
      "             '  booktitle={NIPS},\\n'\n",
      "             '  year={2015}\\n'\n",
      "             '}',\n",
      " 'description': 'AG is a collection of more than 1 million news articles. News '\n",
      "                'articles have been\\n'\n",
      "                'gathered from more than 2000 news sources by ComeToMyHead in '\n",
      "                'more than 1 year of\\n'\n",
      "                'activity. ComeToMyHead is an academic news search engine '\n",
      "                'which has been running\\n'\n",
      "                'since July, 2004. The dataset is provided by the academic '\n",
      "                'comunity for research\\n'\n",
      "                'purposes in data mining (clustering, classification, etc), '\n",
      "                'information retrieval\\n'\n",
      "                '(ranking, search, etc), xml, data compression, data '\n",
      "                'streaming, and any other\\n'\n",
      "                'non-commercial activity. For more information, please refer '\n",
      "                'to the link\\n'\n",
      "                'http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html '\n",
      "                '.\\n'\n",
      "                '\\n'\n",
      "                \"The AG's news topic classification dataset is constructed by \"\n",
      "                'Xiang Zhang\\n'\n",
      "                '(xiang.zhang@nyu.edu) from the dataset above. It is used as a '\n",
      "                'text\\n'\n",
      "                'classification benchmark in the following paper: Xiang Zhang, '\n",
      "                'Junbo Zhao, Yann\\n'\n",
      "                'LeCun. Character-level Convolutional Networks for Text '\n",
      "                'Classification. Advances\\n'\n",
      "                'in Neural Information Processing Systems 28 (NIPS 2015).',\n",
      " 'etag': '\"560ac59ac8cb6f76ac4180562a7f9342\"',\n",
      " 'id': 'ag_news',\n",
      " 'key': 'datasets/datasets/ag_news/ag_news.py',\n",
      " 'lastModified': '2020-09-15T08:26:31.000Z',\n",
      " 'numModels': 1,\n",
      " 'siblings': [datasets.S3Object('ag_news.py'),\n",
      "              datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/0.0.0/dummy_data.zip')],\n",
      " 'size': 3991}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t C4\n",
      "{'author': None,\n",
      " 'citation': '@article{2019t5,\\n'\n",
      "             '    author = {Colin Raffel and Noam Shazeer and Adam Roberts and '\n",
      "             'Katherine Lee and Sharan Narang and Michael Matena and Yanqi '\n",
      "             'Zhou and Wei Li and Peter J. Liu},\\n'\n",
      "             '    title = {Exploring the Limits of Transfer Learning with a '\n",
      "             'Unified Text-to-Text Transformer},\\n'\n",
      "             '    journal = {arXiv e-prints},\\n'\n",
      "             '    year = {2019},\\n'\n",
      "             '    archivePrefix = {arXiv},\\n'\n",
      "             '    eprint = {1910.10683},\\n'\n",
      "             '}',\n",
      " 'description': \"A colossal, cleaned version of Common Crawl's web crawl \"\n",
      "                'corpus.\\n'\n",
      "                '\\n'\n",
      "                'Based on Common Crawl dataset: \"https://commoncrawl.org\"\\n'\n",
      "                '\\n'\n",
      "                'Due to the overhead of cleaning the dataset, it is recommend '\n",
      "                'you prepare it with\\n'\n",
      "                'a distributed service like Cloud Dataflow. More info at\\n'\n",
      "                'https://www.tensorflow.org/datasets/beam_datasets.',\n",
      " 'etag': '\"ef21b9a94927daacf55fd94b0690c4e0\"',\n",
      " 'id': 'c4',\n",
      " 'key': 'datasets/datasets/c4/c4.py',\n",
      " 'lastModified': '2020-09-28T10:26:15.000Z',\n",
      " 'numModels': 5,\n",
      " 'siblings': [datasets.S3Object('c4.py'), datasets.S3Object('c4_utils.py')],\n",
      " 'size': 13572}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t CNN_DAILYMAIL\n",
      "{'author': None,\n",
      " 'citation': '@article{DBLP:journals/corr/SeeLM17,\\n'\n",
      "             '  author    = {Abigail See and\\n'\n",
      "             '               Peter J. Liu and\\n'\n",
      "             '               Christopher D. Manning},\\n'\n",
      "             '  title     = {Get To The Point: Summarization with '\n",
      "             'Pointer-Generator Networks},\\n'\n",
      "             '  journal   = {CoRR},\\n'\n",
      "             '  volume    = {abs/1704.04368},\\n'\n",
      "             '  year      = {2017},\\n'\n",
      "             '  url       = {http://arxiv.org/abs/1704.04368},\\n'\n",
      "             '  archivePrefix = {arXiv},\\n'\n",
      "             '  eprint    = {1704.04368},\\n'\n",
      "             '  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\\n'\n",
      "             '  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\\n'\n",
      "             '  bibsource = {dblp computer science bibliography, '\n",
      "             'https://dblp.org}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{hermann2015teaching,\\n'\n",
      "             '  title={Teaching machines to read and comprehend},\\n'\n",
      "             '  author={Hermann, Karl Moritz and Kocisky, Tomas and '\n",
      "             'Grefenstette, Edward and Espeholt, Lasse and Kay, Will and '\n",
      "             'Suleyman, Mustafa and Blunsom, Phil},\\n'\n",
      "             '  booktitle={Advances in neural information processing '\n",
      "             'systems},\\n'\n",
      "             '  pages={1693--1701},\\n'\n",
      "             '  year={2015}\\n'\n",
      "             '}',\n",
      " 'description': 'CNN/DailyMail non-anonymized summarization dataset.\\n'\n",
      "                '\\n'\n",
      "                'There are two features:\\n'\n",
      "                '  - article: text of news article, used as the document to be '\n",
      "                'summarized\\n'\n",
      "                '  - highlights: joined text of highlights with <s> and </s> '\n",
      "                'around each\\n'\n",
      "                '    highlight, which is the target summary',\n",
      " 'etag': '\"c5a29813057055f54e1aabac51059915\"',\n",
      " 'id': 'cnn_dailymail',\n",
      " 'key': 'datasets/datasets/cnn_dailymail/cnn_dailymail.py',\n",
      " 'lastModified': '2020-09-15T08:26:31.000Z',\n",
      " 'numModels': 11,\n",
      " 'siblings': [datasets.S3Object('cnn_dailymail.py'),\n",
      "              datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/1.0.0/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/2.0.0/2.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/3.0.0/3.0.0/dummy_data.zip')],\n",
      " 'size': 9384}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t GIGAWORD\n",
      "{'author': None,\n",
      " 'citation': '@article{graff2003english,\\n'\n",
      "             '  title={English gigaword},\\n'\n",
      "             '  author={Graff, David and Kong, Junbo and Chen, Ke and Maeda, '\n",
      "             'Kazuaki},\\n'\n",
      "             '  journal={Linguistic Data Consortium, Philadelphia},\\n'\n",
      "             '  volume={4},\\n'\n",
      "             '  number={1},\\n'\n",
      "             '  pages={34},\\n'\n",
      "             '  year={2003}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@article{Rush_2015,\\n'\n",
      "             '   title={A Neural Attention Model for Abstractive Sentence '\n",
      "             'Summarization},\\n'\n",
      "             '   url={http://dx.doi.org/10.18653/v1/D15-1044},\\n'\n",
      "             '   DOI={10.18653/v1/d15-1044},\\n'\n",
      "             '   journal={Proceedings of the 2015 Conference on Empirical '\n",
      "             'Methods in Natural Language Processing},\\n'\n",
      "             '   publisher={Association for Computational Linguistics},\\n'\n",
      "             '   author={Rush, Alexander M. and Chopra, Sumit and Weston, '\n",
      "             'Jason},\\n'\n",
      "             '   year={2015}\\n'\n",
      "             '}',\n",
      " 'description': 'Headline-generation on a corpus of article pairs from '\n",
      "                'Gigaword consisting of\\n'\n",
      "                \"around 4 million articles. Use the 'org_data' provided by\\n\"\n",
      "                'https://github.com/microsoft/unilm/ which is identical to\\n'\n",
      "                'https://github.com/harvardnlp/sent-summary but with better '\n",
      "                'format.\\n'\n",
      "                '\\n'\n",
      "                'There are two features:\\n'\n",
      "                '  - document: article.\\n'\n",
      "                '  - summary: headline.',\n",
      " 'etag': '\"ea529a40325b26a2166373589821efe6\"',\n",
      " 'id': 'gigaword',\n",
      " 'key': 'datasets/datasets/gigaword/gigaword.py',\n",
      " 'lastModified': '2020-09-15T08:26:31.000Z',\n",
      " 'numModels': 12,\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/1.2.0/dummy_data.zip'),\n",
      "              datasets.S3Object('gigaword.py')],\n",
      " 'size': 4465}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t GUARDIAN_AUTHORSHIP\n",
      "{'author': None,\n",
      " 'citation': '@article{article,\\n'\n",
      "             '    author = {Stamatatos, Efstathios},\\n'\n",
      "             '    year = {2013},\\n'\n",
      "             '    month = {01},\\n'\n",
      "             '    pages = {421-439},\\n'\n",
      "             '    title = {On the robustness of authorship attribution based '\n",
      "             'on character n-gram features},\\n'\n",
      "             '    volume = {21},\\n'\n",
      "             '    journal = {Journal of Law and Policy}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{stamatatos2017authorship,\\n'\n",
      "             '    title={Authorship attribution using text distortion},\\n'\n",
      "             '    author={Stamatatos, Efstathios},\\n'\n",
      "             '    booktitle={Proc. of the 15th Conf. of the European Chapter '\n",
      "             'of the Association for Computational Linguistics},\\n'\n",
      "             '    volume={1}\\n'\n",
      "             '    pages={1138--1149},\\n'\n",
      "             '    year={2017}\\n'\n",
      "             '}',\n",
      " 'description': 'A dataset cross-topic authorship attribution. The dataset is '\n",
      "                'provided by Stamatatos 2013.\\n'\n",
      "                '1- The cross-topic scenarios are based on Table-4 in '\n",
      "                'Stamatatos 2017 (Ex. cross_topic_1 => row 1:P S U&W ).\\n'\n",
      "                '2- The cross-genre scenarios are based on Table-5 in the same '\n",
      "                'paper. (Ex. cross_genre_1 => row 1:B P S&U&W).\\n'\n",
      "                '\\n'\n",
      "                '3- The same-topic/genre scenario is created by grouping all '\n",
      "                'the datasts as follows.\\n'\n",
      "                'For ex., to use same_topic and split the data 60-40 use:\\n'\n",
      "                \"train_ds = load_dataset('guardian_authorship', \"\n",
      "                'name=\"cross_topic_<<#>>\",\\n'\n",
      "                '                        '\n",
      "                \"split='train[:60%]+validation[:60%]+test[:60%]')\\n\"\n",
      "                \"tests_ds = load_dataset('guardian_authorship', \"\n",
      "                'name=\"cross_topic_<<#>>\",\\n'\n",
      "                '                        '\n",
      "                \"split='train[-40%:]+validation[-40%:]+test[-40%:]')\\n\"\n",
      "                '\\n'\n",
      "                'IMPORTANT: train+validation+test[:60%] will generate the '\n",
      "                'wrong splits becasue the data is imbalanced\\n'\n",
      "                '\\n'\n",
      "                '* See https://huggingface.co/docs/datasets/splits.html for '\n",
      "                'detailed/more examples',\n",
      " 'etag': '\"116a2c5cdd08f35a7fc3278aa876af80\"',\n",
      " 'id': 'guardian_authorship',\n",
      " 'key': 'datasets/datasets/guardian_authorship/guardian_authorship.py',\n",
      " 'lastModified': '2020-09-15T08:26:31.000Z',\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/cross_genre_1/13.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_genre_2/14.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_genre_3/15.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_genre_4/16.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_1/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_10/10.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_11/11.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_12/12.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_2/2.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_3/3.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_4/4.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_5/5.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_6/6.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_7/7.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_8/8.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/cross_topic_9/9.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('guardian_authorship.py')],\n",
      " 'size': 14330}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t MULTI_NEWS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': None,\n",
      " 'citation': '@misc{alex2019multinews,\\n'\n",
      "             '    title={Multi-News: a Large-Scale Multi-Document '\n",
      "             'Summarization Dataset and Abstractive Hierarchical Model},\\n'\n",
      "             '    author={Alexander R. Fabbri and Irene Li and Tianwei She and '\n",
      "             'Suyi Li and Dragomir R. Radev},\\n'\n",
      "             '    year={2019},\\n'\n",
      "             '    eprint={1906.01749},\\n'\n",
      "             '    archivePrefix={arXiv},\\n'\n",
      "             '    primaryClass={cs.CL}\\n'\n",
      "             '}',\n",
      " 'description': 'Multi-News, consists of news articles and human-written '\n",
      "                'summaries\\n'\n",
      "                'of these articles from the site newser.com.\\n'\n",
      "                'Each summary is professionally written by editors and\\n'\n",
      "                'includes links to the original articles cited.\\n'\n",
      "                '\\n'\n",
      "                'There are two features:\\n'\n",
      "                '  - document: text of news articles seperated by special '\n",
      "                'token \"|||||\".\\n'\n",
      "                '  - summary: news summary.',\n",
      " 'etag': '\"8802f5d267c5e0ca913adac7cfdbe597\"',\n",
      " 'id': 'multi_news',\n",
      " 'key': 'datasets/datasets/multi_news/multi_news.py',\n",
      " 'lastModified': '2020-09-15T08:26:32.000Z',\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('multi_news.py')],\n",
      " 'size': 3679}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t NEWSGROUP\n",
      "{'author': None,\n",
      " 'citation': '@inproceedings{Lang95,\\n'\n",
      "             '    author = {Ken Lang},\\n'\n",
      "             '    title = {Newsweeder: Learning to filter netnews}\\n'\n",
      "             '    year = {1995}\\n'\n",
      "             '    booktitle = {Proceedings of the Twelfth International '\n",
      "             'Conference on Machine Learning}\\n'\n",
      "             '    pages = {331-339}\\n'\n",
      "             '    }',\n",
      " 'description': 'The 20 Newsgroups data set is a collection of approximately '\n",
      "                '20,000 newsgroup documents, partitioned (nearly) evenly '\n",
      "                'across\\n'\n",
      "                '20 different newsgroups. The 20 newsgroups collection has '\n",
      "                'become a popular data set for experiments in text '\n",
      "                'applications of\\n'\n",
      "                'machine learning techniques, such as text classification and '\n",
      "                'text clustering.',\n",
      " 'etag': '\"df83f01089db317900097ce0b756182d\"',\n",
      " 'id': 'newsgroup',\n",
      " 'key': 'datasets/datasets/newsgroup/newsgroup.py',\n",
      " 'lastModified': '2020-09-15T08:26:32.000Z',\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/18828_alt.atheism/3.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('newsgroup.py')],\n",
      " 'size': 5578}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t NEWSROOM\n",
      "{'author': None,\n",
      " 'citation': '@inproceedings{N18-1065,\\n'\n",
      "             '  author    = {Grusky, Max and Naaman, Mor and Artzi, Yoav},\\n'\n",
      "             '  title     = {NEWSROOM: A Dataset of 1.3 Million Summaries\\n'\n",
      "             '               with Diverse Extractive Strategies},\\n'\n",
      "             '  booktitle = {Proceedings of the 2018 Conference of the\\n'\n",
      "             '               North American Chapter of the Association for\\n'\n",
      "             '               Computational Linguistics: Human Language '\n",
      "             'Technologies},\\n'\n",
      "             '  year      = {2018},\\n'\n",
      "             '}',\n",
      " 'description': 'NEWSROOM is a large dataset for training and evaluating '\n",
      "                'summarization systems.\\n'\n",
      "                'It contains 1.3 million articles and summaries written by '\n",
      "                'authors and\\n'\n",
      "                'editors in the newsrooms of 38 major publications.\\n'\n",
      "                '\\n'\n",
      "                'Dataset features includes:\\n'\n",
      "                '  - text: Input news text.\\n'\n",
      "                '  - summary: Summary for the news.\\n'\n",
      "                'And additional features:\\n'\n",
      "                '  - title: news title.\\n'\n",
      "                '  - url: url of the news.\\n'\n",
      "                '  - date: date of the article.\\n'\n",
      "                '  - density: extractive density.\\n'\n",
      "                '  - coverage: extractive coverage.\\n'\n",
      "                '  - compression: compression ratio.\\n'\n",
      "                '  - density_bin: low, medium, high.\\n'\n",
      "                '  - coverage_bin: extractive, abstractive.\\n'\n",
      "                '  - compression_bin: low, medium, high.\\n'\n",
      "                '\\n'\n",
      "                'This dataset can be downloaded upon requests. Unzip all the '\n",
      "                'contents\\n'\n",
      "                '\"train.jsonl, dev.josnl, test.jsonl\" to the tfds folder.',\n",
      " 'etag': '\"aab8321975a1c72e5de3c82e9bb37b5a\"',\n",
      " 'id': 'newsroom',\n",
      " 'key': 'datasets/datasets/newsroom/newsroom.py',\n",
      " 'lastModified': '2020-09-15T08:26:32.000Z',\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('newsroom.py')],\n",
      " 'size': 5206}\n",
      "--------------------------------------------------\n",
      "DATASET\t|\t REUTERS21578\n",
      "{'author': None,\n",
      " 'citation': '@article{APTE94,\\n'\n",
      "             \"author = {Chidanand Apt{\\\\'{e}} and Fred Damerau and Sholom M. \"\n",
      "             'Weiss},\\n'\n",
      "             'title = {Automated Learning of Decision Rules for Text '\n",
      "             'Categorization},\\n'\n",
      "             'journal = {ACM Transactions on Information Systems},\\n'\n",
      "             'year = {1994},\\n'\n",
      "             'note = {To appear.}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{APTE94b,\\n'\n",
      "             \"author = {Chidanand Apt{\\\\'{e}} and Fred Damerau and Sholom M. \"\n",
      "             'Weiss},\\n'\n",
      "             'title = {Toward Language Independent Automated Learning of Text '\n",
      "             'Categorization Models},\\n'\n",
      "             'booktitle = {sigir94},\\n'\n",
      "             'year = {1994},\\n'\n",
      "             'note = {To appear.}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{HAYES8},\\n'\n",
      "             'author = {Philip J. Hayes and Peggy M. Anderson and Irene B. '\n",
      "             'Nirenburg and\\n'\n",
      "             'Linda M. Schmandt},\\n'\n",
      "             'title = {{TCS}: A Shell for Content-Based Text Categorization},\\n'\n",
      "             'booktitle = {IEEE Conference on Artificial Intelligence '\n",
      "             'Applications},\\n'\n",
      "             'year = {1990}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{HAYES90b,\\n'\n",
      "             'author = {Philip J. Hayes and Steven P. Weinstein},\\n'\n",
      "             'title = {{CONSTRUE/TIS:} A System for Content-Based Indexing of '\n",
      "             'a\\n'\n",
      "             'Database of News Stories},\\n'\n",
      "             'booktitle = {Second Annual Conference on Innovative Applications '\n",
      "             'of\\n'\n",
      "             'Artificial Intelligence},\\n'\n",
      "             'year = {1990}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@incollection{HAYES92 ,\\n'\n",
      "             'author = {Philip J. Hayes},\\n'\n",
      "             'title = {Intelligent High-Volume Text Processing using Shallow,\\n'\n",
      "             'Domain-Specific Techniques},\\n'\n",
      "             'booktitle = {Text-Based Intelligent Systems},\\n'\n",
      "             'publisher = {Lawrence Erlbaum},\\n'\n",
      "             'address =  {Hillsdale, NJ},\\n'\n",
      "             'year = {1992},\\n'\n",
      "             'editor = {Paul S. Jacobs}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS91c ,\\n'\n",
      "             'author = {David D. Lewis},\\n'\n",
      "             'title = {Evaluating Text Categorization},\\n'\n",
      "             'booktitle = {Proceedings of Speech and Natural Language '\n",
      "             'Workshop},\\n'\n",
      "             'year = {1991},\\n'\n",
      "             'month = {feb},\\n'\n",
      "             'organization = {Defense Advanced Research Projects Agency},\\n'\n",
      "             'publisher = {Morgan Kaufmann},\\n'\n",
      "             'pages = {312--318}\\n'\n",
      "             '\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@phdthesis{LEWIS91d,\\n'\n",
      "             'author = {David Dolan Lewis},\\n'\n",
      "             'title = {Representation and Learning in Information Retrieval},\\n'\n",
      "             'school = {Computer Science Dept.; Univ. of Massachusetts; '\n",
      "             'Amherst, MA 01003},\\n'\n",
      "             'year = 1992},\\n'\n",
      "             'note = {Technical Report 91--93.}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS91e,\\n'\n",
      "             'author = {David D. Lewis},\\n'\n",
      "             'title = {Data Extraction as Text Categorization: An Experiment '\n",
      "             'with\\n'\n",
      "             'the {MUC-3} Corpus},\\n'\n",
      "             'booktitle = {Proceedings of the Third Message Understanding '\n",
      "             'Evaluation\\n'\n",
      "             'and Conference},\\n'\n",
      "             'year = {1991},\\n'\n",
      "             'month = {may},\\n'\n",
      "             'organization = {Defense Advanced Research Projects Agency},\\n'\n",
      "             'publisher = {Morgan Kaufmann},\\n'\n",
      "             'address = {Los Altos, CA}\\n'\n",
      "             '\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS92b,\\n'\n",
      "             'author = {David D. Lewis},\\n'\n",
      "             'title = {An Evaluation of Phrasal and Clustered Representations '\n",
      "             'on a Text\\n'\n",
      "             'Categorization Task},\\n'\n",
      "             'booktitle = {Fifteenth Annual International ACM SIGIR Conference '\n",
      "             'on\\n'\n",
      "             'Research and Development in Information Retrieval},\\n'\n",
      "             'year = {1992},\\n'\n",
      "             'pages = {37--50}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS92d ,\\n'\n",
      "             'author = {David D. Lewis and Richard M. Tong},\\n'\n",
      "             'title = {Text Filtering in {MUC-3} and {MUC-4}},\\n'\n",
      "             'booktitle = {Proceedings of the Fourth Message Understanding '\n",
      "             'Conference ({MUC-4})},\\n'\n",
      "             'year = {1992},\\n'\n",
      "             'month = {jun},\\n'\n",
      "             'organization = {Defense Advanced Research Projects Agency},\\n'\n",
      "             'publisher = {Morgan Kaufmann},\\n'\n",
      "             'address = {Los Altos, CA}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS92e,\\n'\n",
      "             'author = {David D. Lewis},\\n'\n",
      "             'title = {Feature Selection and Feature Extraction for Text '\n",
      "             'Categorization},\\n'\n",
      "             'booktitle = {Proceedings of Speech and Natural Language '\n",
      "             'Workshop},\\n'\n",
      "             'year = {1992},\\n'\n",
      "             'month = {feb} ,\\n'\n",
      "             'organization = {Defense Advanced Research Projects Agency},\\n'\n",
      "             'publisher = {Morgan Kaufmann},\\n'\n",
      "             'pages = {212--217}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{LEWIS94b,\\n'\n",
      "             'author = {David D. Lewis and Marc Ringuette},\\n'\n",
      "             'title = {A Comparison of Two Learning Algorithms for Text '\n",
      "             'Categorization},\\n'\n",
      "             'booktitle = {Symposium on Document Analysis and Information '\n",
      "             'Retrieval},\\n'\n",
      "             'year = {1994},\\n'\n",
      "             'organization = {ISRI; Univ. of Nevada, Las Vegas},\\n'\n",
      "             'address = {Las Vegas, NV},\\n'\n",
      "             'month = {apr},\\n'\n",
      "             'pages = {81--93}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@article{LEWIS94d,\\n'\n",
      "             'author = {David D. Lewis and Philip J. Hayes},\\n'\n",
      "             'title = {Guest Editorial},\\n'\n",
      "             'journal = {ACM Transactions on Information Systems},\\n'\n",
      "             'year = {1994},\\n'\n",
      "             'volume  = {12},\\n'\n",
      "             'number  = {3},\\n'\n",
      "             'pages = {231},\\n'\n",
      "             'month = {jul}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@article{SPARCKJONES76,\\n'\n",
      "             'author = {K. {Sparck Jones} and  C. J. {van Rijsbergen}},\\n'\n",
      "             'title =  {Information Retrieval Test Collections},\\n'\n",
      "             'journal = {Journal of Documentation},\\n'\n",
      "             'year = {1976},\\n'\n",
      "             'volume = {32},\\n'\n",
      "             'number = {1},\\n'\n",
      "             'pages = {59--75}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@book{WEISS91,\\n'\n",
      "             'author = {Sholom M. Weiss and Casimir A. Kulikowski},\\n'\n",
      "             'title = {Computer Systems That Learn},\\n'\n",
      "             'publisher = {Morgan Kaufmann},\\n'\n",
      "             'year = {1991},\\n'\n",
      "             'address = {San Mateo, CA}\\n'\n",
      "             '}',\n",
      " 'description': 'The Reuters-21578 dataset  is one of the most widely used '\n",
      "                'data collections for text\\n'\n",
      "                'categorization research. It is collected from the Reuters '\n",
      "                'financial newswire service in 1987.',\n",
      " 'etag': '\"f40f9248470a298708d0c03644912c7f\"',\n",
      " 'id': 'reuters21578',\n",
      " 'key': 'datasets/datasets/reuters21578/reuters21578.py',\n",
      " 'lastModified': '2020-09-15T08:26:32.000Z',\n",
      " 'siblings': [datasets.S3Object('dataset_infos.json'),\n",
      "              datasets.S3Object('dummy/ModApte/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/ModHayes/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('dummy/ModLewis/1.0.0/dummy_data.zip'),\n",
      "              datasets.S3Object('reuters21578.py')],\n",
      " 'size': 15531}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "interesting_datasets = ['ag_news', 'c4', 'cnn_dailymail', 'gigaword', 'guardian_authorship', 'multi_news', 'newsgroup', 'newsroom', 'reuters21578']\n",
    "for d in interesting_datasets:\n",
    "    print('DATASET\\t|\\t', d.upper())\n",
    "    pprint(list_datasets(with_details=True)[datasets.index(d)].__dict__)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:42:48.535459 4342402496 filelock.py:274] Lock 140379078818112 acquired on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1022 11:42:48.537261 4342402496 filelock.py:318] Lock 140379078818112 released on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1022 11:42:48.543123 4342402496 filelock.py:274] Lock 140379082139408 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1022 11:42:48.543893 4342402496 filelock.py:318] Lock 140379082139408 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1022 11:42:48.544751 4342402496 filelock.py:274] Lock 140379082138792 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/3.0.0 (download: 558.32 MiB, generated: 1.28 GiB, post-processed: Unknown size, total: 1.82 GiB) to /Users/claartje/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:42:49.053239 4342402496 filelock.py:274] Lock 140379085885000 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/1bc05d24fa6dda2468e83a73cf6dc207226e01e3c48a507ea716dc0421da583b.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bfe57c46824fa79a1ce8a6b308b7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:02.534975 4342402496 filelock.py:318] Lock 140379085885000 released on /Users/claartje/.cache/huggingface/datasets/downloads/1bc05d24fa6dda2468e83a73cf6dc207226e01e3c48a507ea716dc0421da583b.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:02.796048 4342402496 filelock.py:274] Lock 140378976710952 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/cd557e1bbd512173ecb2baef4808edd7d0b2f75afef4243617d0cc280d2e164d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51b3eb0cd4d448e91232cf1585c90d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Downloading', layout=Layout(width='20px…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:39.083689 4342402496 filelock.py:318] Lock 140378976710952 released on /Users/claartje/.cache/huggingface/datasets/downloads/cd557e1bbd512173ecb2baef4808edd7d0b2f75afef4243617d0cc280d2e164d.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:39.420789 4342402496 filelock.py:274] Lock 140378986966824 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/ef4e7f8ac2bbf7438738fb08657f800ac39babfbdc854f6be5476e87a50b5f77.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e1d5e6b28640468d4d0b38782d72a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=626592.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:39.563328 4342402496 filelock.py:318] Lock 140378986966824 released on /Users/claartje/.cache/huggingface/datasets/downloads/ef4e7f8ac2bbf7438738fb08657f800ac39babfbdc854f6be5476e87a50b5f77.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:41.802346 4342402496 filelock.py:274] Lock 140379063568144 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/73c6059982dcf15454bdfd38c7586da19a0c0a16bc163916c59cf3348e36fd09.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761622e022374d7b9c5e94c113e3a4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=13463354.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:43.077105 4342402496 filelock.py:318] Lock 140379063568144 released on /Users/claartje/.cache/huggingface/datasets/downloads/73c6059982dcf15454bdfd38c7586da19a0c0a16bc163916c59cf3348e36fd09.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:43.813400 4342402496 filelock.py:274] Lock 140379085800504 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/202b4c051a2d599aa1c3db61f8005760722a8681be01393b62b8662910d509d5.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc624eb0ea564b75ae26d45d4f5915da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=725406.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:44.065567 4342402496 filelock.py:318] Lock 140379085800504 released on /Users/claartje/.cache/huggingface/datasets/downloads/202b4c051a2d599aa1c3db61f8005760722a8681be01393b62b8662910d509d5.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 11:43:46.550081 4342402496 filelock.py:274] Lock 140379078723568 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/1bc05d24fa6dda2468e83a73cf6dc207226e01e3c48a507ea716dc0421da583b.lock\n",
      "I1022 11:44:29.758170 4342402496 filelock.py:318] Lock 140379078723568 released on /Users/claartje/.cache/huggingface/datasets/downloads/1bc05d24fa6dda2468e83a73cf6dc207226e01e3c48a507ea716dc0421da583b.lock\n",
      "I1022 11:44:29.805727 4342402496 filelock.py:274] Lock 140379085803136 acquired on /Users/claartje/.cache/huggingface/datasets/downloads/cd557e1bbd512173ecb2baef4808edd7d0b2f75afef4243617d0cc280d2e164d.lock\n",
      "I1022 11:46:12.415588 4342402496 filelock.py:318] Lock 140379085803136 released on /Users/claartje/.cache/huggingface/datasets/downloads/cd557e1bbd512173ecb2baef4808edd7d0b2f75afef4243617d0cc280d2e164d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 12:02:03.751269 4342402496 filelock.py:274] Lock 140379081925128 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.incomplete.lock\n",
      "I1022 12:02:03.765397 4342402496 filelock.py:318] Lock 140379081925128 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.incomplete.lock\n",
      "I1022 12:02:03.766872 4342402496 filelock.py:318] Lock 140379082138792 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to /Users/claartje/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602. Subsequent calls will reuse this data.\n",
      "{'builder_name': 'cnn_dailymail',\n",
      " 'citation': '@article{DBLP:journals/corr/SeeLM17,\\n'\n",
      "             '  author    = {Abigail See and\\n'\n",
      "             '               Peter J. Liu and\\n'\n",
      "             '               Christopher D. Manning},\\n'\n",
      "             '  title     = {Get To The Point: Summarization with '\n",
      "             'Pointer-Generator Networks},\\n'\n",
      "             '  journal   = {CoRR},\\n'\n",
      "             '  volume    = {abs/1704.04368},\\n'\n",
      "             '  year      = {2017},\\n'\n",
      "             '  url       = {http://arxiv.org/abs/1704.04368},\\n'\n",
      "             '  archivePrefix = {arXiv},\\n'\n",
      "             '  eprint    = {1704.04368},\\n'\n",
      "             '  timestamp = {Mon, 13 Aug 2018 16:46:08 +0200},\\n'\n",
      "             '  biburl    = {https://dblp.org/rec/bib/journals/corr/SeeLM17},\\n'\n",
      "             '  bibsource = {dblp computer science bibliography, '\n",
      "             'https://dblp.org}\\n'\n",
      "             '}\\n'\n",
      "             '\\n'\n",
      "             '@inproceedings{hermann2015teaching,\\n'\n",
      "             '  title={Teaching machines to read and comprehend},\\n'\n",
      "             '  author={Hermann, Karl Moritz and Kocisky, Tomas and '\n",
      "             'Grefenstette, Edward and Espeholt, Lasse and Kay, Will and '\n",
      "             'Suleyman, Mustafa and Blunsom, Phil},\\n'\n",
      "             '  booktitle={Advances in neural information processing '\n",
      "             'systems},\\n'\n",
      "             '  pages={1693--1701},\\n'\n",
      "             '  year={2015}\\n'\n",
      "             '}\\n',\n",
      " 'config_name': '3.0.0',\n",
      " 'dataset_size': 1369362499,\n",
      " 'description': 'CNN/DailyMail non-anonymized summarization dataset.\\n'\n",
      "                '\\n'\n",
      "                'There are two features:\\n'\n",
      "                '  - article: text of news article, used as the document to be '\n",
      "                'summarized\\n'\n",
      "                '  - highlights: joined text of highlights with <s> and </s> '\n",
      "                'around each\\n'\n",
      "                '    highlight, which is the target summary\\n',\n",
      " 'download_checksums': {'https://drive.google.com/uc?export=download&id=0BwmD_VLjROrfM1BxdkxVaTY2bWs': {'checksum': 'ad69010002210b7c406718248ee66e65868b9f6820f163aa966369878d14147e',\n",
      "                                                                                                        'num_bytes': 375893739},\n",
      "                        'https://drive.google.com/uc?export=download&id=0BwmD_VLjROrfTHk4NFg2SndKcjQ': {'checksum': 'e8fbc0027e54e0a916abd9c969eb35f708ed1467d7ef4e3b17a56739d65cb200',\n",
      "                                                                                                        'num_bytes': 158577824},\n",
      "                        'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_test.txt': {'checksum': 'c4f5efb5ec2126430a5c156efbd13d0e9c4cb490169e552c38b4a51981a009bd',\n",
      "                                                                                                                 'num_bytes': 2109547},\n",
      "                        'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_train.txt': {'checksum': 'a5cee49f3a6c862c26ce29308236d2a99625ab6c86a43be22d5206b2790d8029',\n",
      "                                                                                                                  'num_bytes': 46424688},\n",
      "                        'https://raw.githubusercontent.com/abisee/cnn-dailymail/master/url_lists/all_val.txt': {'checksum': '81887e982b045083409c6ee838aede8ff4b97291605bcfb21bffc456a16991db',\n",
      "                                                                                                                'num_bytes': 2433674}},\n",
      " 'download_size': 585439472,\n",
      " 'features': {'article': Value(dtype='string', id=None),\n",
      "              'highlights': Value(dtype='string', id=None),\n",
      "              'id': Value(dtype='string', id=None)},\n",
      " 'homepage': 'https://github.com/abisee/cnn-dailymail',\n",
      " 'license': '',\n",
      " 'post_processed': None,\n",
      " 'post_processing_size': None,\n",
      " 'size_in_bytes': 1954801971,\n",
      " 'splits': {'test': SplitInfo(name='test', num_bytes=49925756, num_examples=11490, dataset_name='cnn_dailymail'),\n",
      "            'train': SplitInfo(name='train', num_bytes=1261704307, num_examples=287113, dataset_name='cnn_dailymail'),\n",
      "            'validation': SplitInfo(name='validation', num_bytes=57732436, num_examples=13368, dataset_name='cnn_dailymail')},\n",
      " 'supervised_keys': None,\n",
      " 'version': 3.0.0}\n"
     ]
    }
   ],
   "source": [
    "# Only loaded 10% of the validation set\n",
    "dataset = load_dataset('cnn_dailymail', '3.0.0', split='validation[:10%]')\n",
    "pprint(dataset.info.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast, logging as transformers_logging\n",
    "\n",
    "transformers_logging.set_verbosity_warning()\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 13:52:41.691669 4342402496 filelock.py:274] Lock 140378620623056 acquired on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1022 13:52:41.694133 4342402496 filelock.py:318] Lock 140378620623056 released on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1022 13:52:41.707391 4342402496 filelock.py:274] Lock 140378620651840 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1022 13:52:41.714417 4342402496 filelock.py:318] Lock 140378620651840 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1022 13:52:41.715877 4342402496 filelock.py:274] Lock 140378620652848 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "Reusing dataset cnn_dailymail (/Users/claartje/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n",
      "I1022 13:52:41.721979 4342402496 filelock.py:318] Lock 140378620652848 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import RobertaTokenizerFast, logging as transformers_logging\n",
    "\n",
    "transformers_logging.set_verbosity_warning()\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "# Load our training dataset and tokenizer\n",
    "dataset = load_dataset('cnn_dailymail', '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcec920c3aed47b2a97d971d8c582e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3b2304393149ea800ea3beba39ab0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize our training dataset\n",
    "def convert_to_features(example_batch):    \n",
    "    # Tokenize articles, truncate to max_len (no padding yet!)\n",
    "    encodings = tokenizer(example_batch['text'], truncation=True)\n",
    "    \n",
    "    return encodings\n",
    "\n",
    "encoded_dataset = dataset.map(convert_to_features, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['attention_mask', 'input_ids', 'label', 'text'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format our dataset to outputs torch.Tensor to train a pytorch model\n",
    "columns = ['attention_mask', 'input_ids', 'text']\n",
    "encoded_dataset.set_format(type='torch', columns=columns)\n",
    "\n",
    "# Instantiate a PyTorch Dataloader around our dataset\n",
    "# Let's do dynamic batching (pad on the fly with our own collate_fn)\n",
    "def collate_fn(examples):\n",
    "\n",
    "    print(type(examples))\n",
    "    padded_batch = tokenizer.pad(examples, return_tensors='pt')\n",
    "    print(type(padded_batch))\n",
    "    \n",
    "    return padded_batch\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(encoded_dataset['train'], collate_fn=collate_fn, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-aa4f1d4e9d98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_all_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         )\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, format_type, format_columns, output_all_columns, format_kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m                 \u001b[0mformat_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m             )\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_convert_outputs\u001b[0;34m(self, outputs, format_type, format_columns, output_all_columns, format_kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_nested_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m                 \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mdisable_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetEffectiveLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/thesisenv-local/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytorch tensors cannot be instantied from an array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmap_nested_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mformat_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorflow\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesisenv-local]",
   "language": "python",
   "name": "conda-env-thesisenv-local-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
