{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_wrappper import NewsData\n",
    "from utils_train import transfer_batch_to_device\n",
    "import os\n",
    "from run_validation import load_model_for_eval\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import RobertaTokenizerFast\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils_evaluation import tokenizer_batch_decode\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "plt.style.reload_library()\n",
    "plt.style.use('thesis_style')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cuda:0\"\n",
    "CHECKPOINT_TYPE = \"best\" # else \"best\"\n",
    "RESULT_DIR = Path(\"result-files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is file!\n",
      "train 42068\n",
      "validation 3370\n",
      "test 3761\n",
      "106 batches with batch size 32\n"
     ]
    }
   ],
   "source": [
    "data = NewsData(batch_size=BATCH_SIZE, tokenizer_name=\"roberta\", dataset_name=\"ptb_text_only\", max_seq_len=64)\n",
    "validation_loader = data.val_dataloader(batch_size=BATCH_SIZE)\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "print(f\"{len(validation_loader)} batches with batch size {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_name(run_name):\n",
    "    latent_size = run_name.split(\"-\")[4][-2:]\n",
    "    if \"autoencoder\" in run_name:\n",
    "        FB = \"autoencoder\"\n",
    "    else:\n",
    "        FB = run_name.split(\"-\")[6]\n",
    "        if len(FB) == 3:\n",
    "            FB += \"0\"\n",
    "        FB = \"FB-\" + FB\n",
    "    clean_name = f\"NZ-{latent_size} | {FB}\"\n",
    "    return clean_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NZ-32 | FB-0.50\n",
      "NZ-32 | FB-1.00\n",
      "NZ-32 | FB-1.50\n",
      "NZ-64 | FB-1.00\n",
      "NZ-32 | FB-0.00\n",
      "NZ-32 | autoencoder\n",
      "NZ-64 | FB-0.50\n",
      "NZ-64 | FB-1.50\n",
      "NZ-64 | FB-0.00\n",
      "NZ-64 | autoencoder\n",
      "NZ-32 | FB-0.75\n",
      "NZ-32 | FB-0.25\n",
      "NZ-64 | FB-0.75\n",
      "NZ-64 | FB-0.25\n"
     ]
    }
   ],
   "source": [
    "PTB_run_name_paths = {}\n",
    "for r in os.listdir(\"/home/cbarkhof/code-thesis/NewsVAE/Runs\"):\n",
    "    if \"PTB\" in r:\n",
    "        path = Path(\"/home/cbarkhof/code-thesis/NewsVAE/Runs\") / r / f\"checkpoint-{CHECKPOINT_TYPE}.pth\"\n",
    "        PTB_run_name_paths[r] = path\n",
    "\n",
    "for r in PTB_run_name_paths.keys():\n",
    "    print(get_clean_name(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-0.5-run-09:31:02/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-1.0-run-11:43:17/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-1.50-run-12:13:36/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent64-FB-1.0-run-13:06:00/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-0.00-run-14:32:09/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-autoencoder-run-17:30:41/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent64-FB-0.50-run-12:29:58/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent64-FB-1.50-run-13:22:14/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent64-FB-0.00-run-17:14:10/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent64-autoencoder-run-18:25:57/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-02-PTB-latent32-FB-0.75-run-12:44:32/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-02-PTB-latent32-FB-0.25-run-13:16:32/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-02-PTB-latent64-FB-0.75-run-13:16:36/checkpoint-best.pth\n",
      "\n",
      "/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-02-PTB-latent64-FB-0.25-run-13:17:02/checkpoint-best.pth\n",
      "\n",
      "Loading model...\n",
      "Replacing linear output layer with one without bias!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing VAE_Encoder_RobertaModel: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing VAE_Encoder_RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VAE_Encoder_RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VAE_Encoder_RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tying encoder decoder RoBERTa checkpoint weights!\n",
      "<class 'modules.decoder_roberta_new.VaeDecoderRobertaModel'> and <class 'modules.encoder_roberta.VAE_Encoder_RobertaModel'> are not equal. In this case make sure that all encoder weights are correctly initialized. \n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "Tying embedding spaces!\n",
      "Done model...\n",
      "Loading VAE_model, optimizer and scheduler from /home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-0.5-run-09:31:02/checkpoint-best.pth\n",
      "Removing module string from state dict from checkpoint\n",
      "Checkpoint global_step: best, epoch: 37, best_valid_loss: 84.10610651086878\n"
     ]
    }
   ],
   "source": [
    "for p in PTB_run_name_paths.values():\n",
    "    print(p)\n",
    "    print()\n",
    "\n",
    "p = \"/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-FB-0.5-run-09:31:02/checkpoint-best.pth\"\n",
    "\n",
    "latent_size = 32\n",
    "\n",
    "vae_model = load_model_for_eval(p, device_name=\"cuda:0\", \n",
    "                                latent_size=latent_size, \n",
    "                                add_latent_via_memory=True,\n",
    "                                add_latent_via_embeddings=False, \n",
    "                                do_tie_weights=True, \n",
    "                                do_tie_embedding_spaces=True,\n",
    "                                add_decoder_output_embedding_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Replacing linear output layer with one without bias!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing VAE_Encoder_RobertaModel: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing VAE_Encoder_RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing VAE_Encoder_RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VAE_Encoder_RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tying encoder decoder RoBERTa checkpoint weights!\n",
      "<class 'modules.decoder_roberta_new.VaeDecoderRobertaModel'> and <class 'modules.encoder_roberta.VAE_Encoder_RobertaModel'> are not equal. In this case make sure that all encoder weights are correctly initialized. \n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "Tying embedding spaces!\n",
      "Done model...\n",
      "Loading VAE_model, optimizer and scheduler from /home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-autoencoder-run-17:30:41/checkpoint-best.pth\n",
      "Removing module string from state dict from checkpoint\n",
      "Checkpoint global_step: best, epoch: 56, best_valid_loss: 62.82812358714916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbarkhof/.conda/envs/thesisenv/lib/python3.6/site-packages/datasets/arrow_dataset.py:847: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n",
      "/home/cbarkhof/.conda/envs/thesisenv/lib/python3.6/site-packages/datasets/arrow_dataset.py:847: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n",
      "/home/cbarkhof/.conda/envs/thesisenv/lib/python3.6/site-packages/datasets/arrow_dataset.py:847: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n",
      "/home/cbarkhof/.conda/envs/thesisenv/lib/python3.6/site-packages/datasets/arrow_dataset.py:847: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0/106\n",
      "Average length: tensor(25.9375, device='cuda:0')\n",
      "latent_z.shape torch.Size([32, 1000, 32])\n",
      "tensor(7.4469e-40, device='cuda:0') tensor(inf, device='cuda:0')\n",
      "sample i:   0\n",
      "sample i:   1\n",
      "sample i:   2\n",
      "sample i:   3\n",
      "sample i:   4\n",
      "sample i:   5\n",
      "sample i:   6\n",
      "sample i:   7\n",
      "sample i:   8\n",
      "sample i:   9\n",
      "sample i:  10\n",
      "sample i:  11\n",
      "sample i:  12\n",
      "sample i:  13\n",
      "sample i:  14\n",
      "sample i:  15\n",
      "sample i:  16\n",
      "sample i:  17\n",
      "sample i:  18\n",
      "sample i:  19\n",
      "sample i:  20\n",
      "sample i:  21\n",
      "sample i:  22\n",
      "sample i:  23\n",
      "sample i:  24\n",
      "sample i:  25\n",
      "sample i:  26\n",
      "sample i:  27\n",
      "sample i:  28\n",
      "sample i:  29\n",
      "sample i:  30\n",
      "sample i:  31\n",
      "ce per word: 2.89 | D: 78.99\n",
      "log p x p w: 10.04 | ppl: 22993.521484\n",
      "  1/106\n",
      "Average length: tensor(26.8438, device='cuda:0')\n",
      "latent_z.shape torch.Size([32, 1000, 32])\n",
      "tensor(1.4122e-40, device='cuda:0') tensor(inf, device='cuda:0')\n",
      "sample i:   0\n",
      "sample i:   1\n",
      "sample i:   2\n",
      "sample i:   3\n",
      "sample i:   4\n",
      "sample i:   5\n",
      "sample i:   6\n",
      "sample i:   7\n",
      "sample i:   8\n",
      "sample i:   9\n",
      "sample i:  10\n",
      "sample i:  11\n",
      "sample i:  12\n",
      "sample i:  13\n",
      "sample i:  14\n",
      "sample i:  15\n",
      "sample i:  16\n",
      "sample i:  17\n",
      "sample i:  18\n",
      "sample i:  19\n",
      "sample i:  20\n",
      "sample i:  21\n",
      "sample i:  22\n",
      "sample i:  23\n",
      "sample i:  24\n",
      "sample i:  25\n",
      "sample i:  26\n",
      "sample i:  27\n",
      "sample i:  28\n",
      "sample i:  29\n",
      "sample i:  30\n",
      "sample i:  31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-f4530cec3796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                                         \u001b[0mreturn_cross_entropy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                                                         \u001b[0mreduce_seq_dim_ce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                                                         reduce_batch_dim_ce=\"none\")\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Auto-regressive decoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, latent_z, input_ids, attention_mask, labels, return_attention_probs, return_attention_to_latent, return_hidden_states, return_exact_match, return_predictions, return_probabilities, return_last_hidden_state, return_logits, return_output_word_embeddings, return_cross_entropy, reduce_seq_dim_exact_match, reduce_batch_dim_exact_match, reduce_seq_dim_ce, reduce_batch_dim_ce, nucleus_sampling, top_k, top_p)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                   \u001b[0mnucleus_sampling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnucleus_sampling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                   \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                   top_p=top_p)\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_outs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, return_attention_probs, return_attention_to_latent, latent_to_decoder_output, return_output_word_embeddings, return_predictions, return_probabilities, return_logits, return_exact_match, return_cross_entropy, reduce_seq_dim_exact_match, reduce_batch_dim_exact_match, reduce_seq_dim_ce, reduce_batch_dim_ce, return_hidden_states, return_last_hidden_state, nucleus_sampling, top_k, top_p)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# >>>>>> Claartje code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[0mlatent_layer_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_layer_memory\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# >>>>>> Claartje code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             \u001b[0mlatent_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_embedding\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# >>>>>> Claartje code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m         )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, latent_layer_memory, latent_embedding, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m         )\n\u001b[1;32m    827\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, latent_layer_memory, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    592\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m                 )\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, latent_memory_i, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         )\n\u001b[1;32m    466\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, latent_layer_memory_i, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    394\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code-thesis/NewsVAE/modules/decoder_roberta_new.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, latent_layer_memory_i, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;31m# so we will concat series of 0.0 to the attention mask (in front) to not mask the latent.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m                 attention_mask_extended_for_memory = torch.cat((extension,\n\u001b[1;32m    300\u001b[0m                                                                 attention_mask), dim=3)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "n_samples = 1000\n",
    "device_name = \"cuda:0\"\n",
    "chunk_size = 100\n",
    "loader = validation_loader\n",
    "\n",
    "N = len(loader)\n",
    "max_batches = 2\n",
    "\n",
    "ppls = []\n",
    "ds = []\n",
    "log_p_xs = []\n",
    "log_p_x_p_ws = []\n",
    "ce_p_ws = []\n",
    "autoregressive = False\n",
    "log_p_x_zs, log_q_z_xs, log_p_zs = [], [], []\n",
    "\n",
    "\n",
    "# for r, p in PTB_run_name_paths.items():\n",
    "p = \"/home/cbarkhof/code-thesis/NewsVAE/Runs/2021-02-03-PTB-latent32-autoencoder-run-17:30:41/checkpoint-best.pth\"\n",
    "    \n",
    "latent_size = 32 if \"latent32\" in r else 64\n",
    "\n",
    "vae_model = load_model_for_eval(p, device_name=\"cuda:0\", \n",
    "                                latent_size=latent_size, \n",
    "                                add_latent_via_memory=True,\n",
    "                                add_latent_via_embeddings=False, \n",
    "                                do_tie_weights=True, \n",
    "                                do_tie_embedding_spaces=True,\n",
    "                                add_decoder_output_embedding_bias=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # For all batches in the validation set\n",
    "    for batch_i, batch in enumerate(loader):\n",
    "        print(f\"{batch_i:3d}/{N}\")\n",
    "\n",
    "        # Send to right device\n",
    "        batch = transfer_batch_to_device(batch, device_name)\n",
    "        batch_size = batch[\"input_ids\"].shape[0]\n",
    "\n",
    "        # Get label mask (where input ids are not 1, which is the padding ID)\n",
    "        labels = copy.deepcopy(batch[\"input_ids\"])[:, 1:].contiguous()\n",
    "        label_mask = (labels != 1).float()\n",
    "        avg_len = label_mask.sum(dim=-1).mean()  # sum where is 1 and average over batch\n",
    "\n",
    "        print(\"Average length:\", avg_len)\n",
    "\n",
    "        # Encode these input ids and sample <n_samples> for each x\n",
    "        enc_out = vae_model.encoder.encode(batch[\"input_ids\"], batch[\"attention_mask\"], \n",
    "                                           n_samples=n_samples, # <-- Number of samples for important sampling\n",
    "                                           hinge_kl_loss_lambda=0.5,\n",
    "                                           return_log_q_z_x=True,\n",
    "                                           return_log_p_z=True,\n",
    "                                           return_embeddings=False)\n",
    "\n",
    "        # Unpack the tensors we need\n",
    "        latent_z, log_p_z, log_q_z_x = enc_out[\"latent_z\"], enc_out[\"log_p_z\"], enc_out[\"log_q_z_x\"]\n",
    "\n",
    "        print(\"latent_z.shape\", latent_z.shape)\n",
    "\n",
    "        print(torch.exp(enc_out[\"log_p_z\"].mean()), torch.exp(enc_out[\"log_q_z_x\"].mean()))\n",
    "\n",
    "        # Now we need to loop again because our batch size was multiplied by n_samples\n",
    "        log_p_x_z = []\n",
    "        ce_per_word = []\n",
    "        distortion = []\n",
    "\n",
    "\n",
    "        # For all samples x in batch\n",
    "        for sample_i in range(batch_size):\n",
    "            print(f\"sample i: {sample_i:3d}\")\n",
    "\n",
    "            # Gather all n_samples z belonging to that x_i\n",
    "            latent_z_sample_i = latent_z[sample_i, :, :]\n",
    "\n",
    "            # Chunk those samples into batches and copy inputs and attention masks to match x (repeat)\n",
    "            input_ids = batch['input_ids'][sample_i, :].repeat(chunk_size, 1)\n",
    "            attention_mask = batch['attention_mask'][sample_i, :].repeat(chunk_size, 1)\n",
    "\n",
    "\n",
    "            n_chunks = int(n_samples / chunk_size)\n",
    "\n",
    "            # Get the mask for this sequence and its length\n",
    "            label_mask_i = label_mask[sample_i, :].repeat(chunk_size, 1)\n",
    "            len_i = label_mask[sample_i, :].sum()\n",
    "\n",
    "            for chunk_i, z_b in enumerate(torch.chunk(latent_z_sample_i, n_chunks, dim=0)):\n",
    "                # Teacher forced decoding\n",
    "                if autoregressive is False:\n",
    "                    dec_out = vae_model.decoder.forward(z_b, input_ids, attention_mask,\n",
    "                                                        labels=copy.deepcopy(input_ids),\n",
    "                                                        return_cross_entropy=True,\n",
    "                                                        reduce_seq_dim_ce=\"none\",\n",
    "                                                        reduce_batch_dim_ce=\"none\")\n",
    "\n",
    "                # Auto-regressive decoding\n",
    "                else:\n",
    "                    dec_out = vae_model.decoder.autoregressive_decode(z_b,\n",
    "                                                                      max_seq_len=input_ids.shape[1],\n",
    "                                                                      device_name=device_name,\n",
    "                                                                      labels=copy.deepcopy(input_ids),\n",
    "                                                                      return_cross_entropy=True,\n",
    "                                                                      reduce_seq_dim_ce=\"none\",\n",
    "                                                                      reduce_batch_dim_ce=\"none\")\n",
    "\n",
    "                # Collect cross entropy per word: multiply with mask, get average over seq and over batch\n",
    "                ce_per_word.append(((dec_out[\"cross_entropy\"] * label_mask_i).sum(dim=-1) / len_i).mean())\n",
    "\n",
    "                # Collect distortion\n",
    "                distortion.append((dec_out[\"cross_entropy\"] * label_mask_i).sum(dim=-1).mean())\n",
    "\n",
    "                # CE = - log p_x_z (not averaged over batch yet)\n",
    "                ce = (dec_out['cross_entropy'] * label_mask_i).sum(dim=-1)\n",
    "\n",
    "                log_p_x_z.append(- ce)\n",
    "\n",
    "            # End of chunk of latents from one data sample\n",
    "\n",
    "        # End of all samples for all data points in batch\n",
    "\n",
    "        # Get mean CE per word and mean distortion\n",
    "        ce_per_word = torch.stack(ce_per_word).mean().item()\n",
    "        distortion = torch.stack(distortion).mean().item()\n",
    "\n",
    "        log_p_x_z = torch.cat(log_p_x_z, dim=0).reshape(-1, n_samples) # make shape batch x n_samples\n",
    "\n",
    "        # Calculate importance weighted perplexity\n",
    "        # log p(x) = log 1/N sum_i^N ( p(x|z_i) * p(z_i) ) / q(z_i|x)\n",
    "        # log p(x) = log sum_i^N exp( log( p(x|z_i) * p(z_i) ) / q(z_i|x) )) + log 1/N\n",
    "        # log p(x) = log sum_i^N exp( log p(x|z_i) + log p(z_i) - log q(z_i|x)) + log 1/N\n",
    "        log_frac = log_p_x_z + log_p_z - log_q_z_x\n",
    "        log_p_x = torch.logsumexp(log_frac, dim=-1) + np.log(1 / n_samples) # do importance weighted mean (over samples)\n",
    "\n",
    "        # importance weighted negative log likelihood per word\n",
    "        log_p_x_p_w = - log_p_x.mean() / avg_len # average over the batch and then words\n",
    "        ppl = torch.exp(log_p_x_p_w)\n",
    "\n",
    "        ppls.append(ppl.item())\n",
    "        ds.append(distortion)\n",
    "        log_p_xs.append(log_p_x.mean().item())\n",
    "        log_p_x_p_ws.append(log_p_x_p_w.item())\n",
    "        ce_p_ws.append(ce_per_word)\n",
    "\n",
    "        log_p_x_zs.append(log_p_x_z.cpu().numpy())\n",
    "        log_q_z_xs.append(log_q_z_x.cpu().numpy())\n",
    "        log_p_zs.append(log_p_z.cpu().numpy())\n",
    "\n",
    "        # print(\"log_p_x_z.shape\", log_p_x_z.shape)\n",
    "        # print(\"log_q_z_x.shape\", log_q_z_x.shape)\n",
    "        # print(\"log_p_z.shape\", log_p_z.shape)\n",
    "\n",
    "        print(f\"ce per word: {ce_per_word:.2f} | D: {distortion:.2f}\")\n",
    "        print(f\"log p x p w: {log_p_x_p_w:.2f} | ppl: {ppl:6f}\")\n",
    "\n",
    "        if batch_i == max_batches - 1:\n",
    "            break\n",
    "\n",
    "    # log_p_x_zs = np.concatenate(log_p_x_zs, axis=0)\n",
    "    # log_q_z_xs = np.concatenate(log_q_z_xs, axis=0)\n",
    "    # log_p_zs = np.concatenate(log_p_zs, axis=0)\n",
    "\n",
    "    # results = dict(PPL=ppls, distortion=ds, log_p_x=log_p_xs, log_p_x_p_w=log_p_x_p_ws, ce_p_w=ce_p_ws,\n",
    "    #                log_p_x_zs=log_p_x_zs, log_q_z_xs=log_q_z_xs, log_p_zs=log_p_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.2040, -2.2625, -0.3351, -0.2449,  0.0886, -0.7174,  0.5582, -2.0932,\n",
      "         0.6206,  0.5095, -0.8901,  1.4365])\n",
      "tensor([[-2.2040, -2.2625, -0.3351, -0.2449],\n",
      "        [ 0.0886, -0.7174,  0.5582, -2.0932],\n",
      "        [ 0.6206,  0.5095, -0.8901,  1.4365]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((12))\n",
    "print(x)\n",
    "print(x.reshape(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = \"autoregressive\"\n",
    "autoregressive = True if mode == \"autoregressive\" else False\n",
    "autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
