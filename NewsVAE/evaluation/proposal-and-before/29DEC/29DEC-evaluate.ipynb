{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch, datasets, transformers, spacy\n",
    "from datasets import load_from_disk\n",
    "from transformers import RobertaTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "# My utils\n",
    "from utils_train import load_from_checkpoint, transfer_batch_to_device\n",
    "from utils_evaluation import tokenizer_batch_decode, reconstruct_autoregressive\n",
    "from train import get_model_on_device\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "# Device\n",
    "device_name = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 13368, number of batches of size 32: 417\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(encoded_samples, tokenizer):\n",
    "    \"\"\"\n",
    "    A function that assembles a batch. This is where padding is done, since it depends on\n",
    "    the maximum sequence length in the batch.\n",
    "\n",
    "    :param examples: list of truncated, tokenised & encoded sequences\n",
    "    :return: padded_batch (batch x max_seq_len)\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine the tensors into a padded batch\n",
    "    padded_batch = tokenizer.pad(encoded_samples, return_tensors='pt')\n",
    "\n",
    "    return padded_batch\n",
    "\n",
    "# VALIDATION DATA\n",
    "valid_dataset = load_from_disk(\"/home/cbarkhof/code-thesis/NewsVAE/NewsData/22DEC-cnn_dailymail-roberta-seqlen64/validation\")\n",
    "\n",
    "# TOKENIZER\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "\n",
    "# TEST DATA LOADER\n",
    "valid_loader = DataLoader(valid_dataset, collate_fn=partial(collate_fn, tokenizer=tokenizer),\n",
    "                          batch_size=batch_size, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "print(f\"Number of test samples: {len(valid_dataset)}, number of batches of size {batch_size}: {int(np.floor(len(valid_dataset) / batch_size))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run names & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp7-AUTO-ENCODER-run-2020-12-29-10:42:11',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp1-CYCLICAL-2-GRADSTEPS-135000-run-2020-12-28-21:40:07',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp3-CYCLICAL-4-GRADSTEPS-6750-run-2020-12-28-21:52:48',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp4-FREEBITS-0.5-ANNEAL-5000-run-2020-12-29-01:17:04',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp5-FREEBITS-0.25-ANNEAL-5000-run-2020-12-29-02:02:31',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp6-FREEBITS-0.125-ANNEAL-5000-run-2020-12-29-04:28:31',\n",
       " '/home/cbarkhof/code-thesis/NewsVAE/Runs/29DEC-exp2-CYCLICAL-3-GRADSTEPS-9000-run-2020-12-29-10:20:01']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_dir = '/home/cbarkhof/code-thesis/NewsVAE/Runs'\n",
    "runs_29DEC_names = [\"-\".join(run_name.split('-')[2:-5]) for run_name in os.listdir(run_dir) if \"29DEC\" in run_name]\n",
    "runs_29DEC_paths = [run_dir + '/' + run_name for run_name in os.listdir(run_dir) if \"29DEC\" in run_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    vae_model = get_model_on_device(device_name=\"cuda:0\", latent_size=768, gradient_checkpointing=False, \n",
    "                                    add_latent_via_memory=True, add_latent_via_embeddings=True,\n",
    "                                    do_tie_weights=True, world_master=True)\n",
    "\n",
    "    _, _, vae_model, _, global_step, epoch, best_valid_loss = load_from_checkpoint(vae_model, path, world_master=True, ddp=False, use_amp=False)\n",
    "    \n",
    "    return vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_pred_text_all = []\n",
    "teacher_correct_all = []\n",
    "teacher_pred_ids_all = []\n",
    "\n",
    "input_text = []\n",
    "\n",
    "autoreg_pred_text_all = []\n",
    "autoreg_correct_all = []\n",
    "autoreg_pred_ids_all = []\n",
    "\n",
    "for batch_i, batch in enumerate(valid_loader):\n",
    "    print(f\"{batch_i+1:5d} / {len(valid_loader):5d}\", end='\\r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch = transfer_batch_to_device(batch)\n",
    "        \n",
    "        # ----- TEACHER-FORCED -------\n",
    "        teacher_output = vae_model.forward(batch[\"input_ids\"], batch[\"attention_mask\"], 1.0, return_predictions=True,\n",
    "                                           return_attention_probs=False, return_exact_match_acc=False, return_latents=False,\n",
    "                                           return_mu_logvar=False, objective='beta-vae', hinge_kl_loss_lambda=0.5)\n",
    "        \n",
    "        # Teacher forced returns batch x 63 (sequence of 62 + end symbol)\n",
    "        teacher_ids = teacher_output[\"predictions\"][:, :-1]\n",
    "        teacher_text = tokenizer_batch_decode(teacher_ids, tokenizer)\n",
    "        \n",
    "        teacher_pred_text_all.append(teacher_text)\n",
    "        teacher_pred_ids_all.append(teacher_ids.cpu())\n",
    "        \n",
    "        # ----- AUTO-REGRESSIVE (with nucleus sampling) -------\n",
    "        autoreg_text, autoreg_ids = reconstruct_autoregressive(vae_model, batch, tokenizer, add_latent_via_embeddings=True,\n",
    "                                                               add_latent_via_memory=True, max_seq_len=64, nucleus_sampling=True,\n",
    "                                                               temperature=1.0, top_k=0, top_p=0.9, device_name=\"cuda:0\",\n",
    "                                                               return_attention_to_latent=False)\n",
    "        \n",
    "        \n",
    "        # Auto-regressive returns batch x 64 (start + sequence of 62 + end symbol)\n",
    "        autoreg_ids = autoreg_ids[:, 1:-1]\n",
    "        autoreg_text = [remove_start_end_token(t) for t in autoreg_text] # remove this post-process\n",
    "        \n",
    "        autoreg_pred_text_all.append(autoreg_text)\n",
    "        autoreg_pred_ids_all.append(autoreg_ids.cpu())\n",
    "        \n",
    "        # ----- INPUT -------\n",
    "        input_ids = batch[\"input_ids\"][:, 1:-1]\n",
    "        input_text = tokenizer_batch_decode(input_ids, tokenizer)\n",
    "        input_text = [remove_start_end_token(t) for t in input_text]\n",
    "        \n",
    "        input_text_all.append(input_text)\n",
    "        input_ids_all.append(input_ids.cpu())\n",
    "                \n",
    "        # ----- EXACT MATCH -------\n",
    "        teacher_correct = (teacher_ids == input_ids).float().cpu()\n",
    "        teacher_correct_all.append(teacher_correct)\n",
    "        \n",
    "        autoreg_correct = (autoreg_ids == input_ids).float().cpu()\n",
    "        autoreg_correct_all.append(autoreg_correct)\n",
    "        \n",
    "        if batch_i == max_batches - 1:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
