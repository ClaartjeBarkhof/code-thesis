{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU :-)...\n",
      "Number of CPU cores: 12\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"../..\")\n",
    "from EncoderDecoderShareVAE import EncoderDecoderShareVAE\n",
    "import NewsVAEArguments\n",
    "import torch\n",
    "from transformers.generation_utils import top_k_top_p_filtering\n",
    "from NewsData import NewsData\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from trainNewsVAE import load_from_checkpoint\n",
    "from utils import transfer_batch_to_device\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import pandas as pd\n",
    "# from pytorch_lightning import seed_everything; seed_everything(0)\n",
    "\n",
    "# Check if on server\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU :-)...\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print(\"Warning: using CPU!\")\n",
    "    device = \"cpu\"\n",
    "    \n",
    "# Overwrite some arguments\n",
    "args = NewsVAEArguments.preprare_parser(jupyter=True, print_settings=False)\n",
    "args.ddp = False\n",
    "args.n_gpus = 1\n",
    "\n",
    "import multiprocessing; print(\"Number of CPU cores: {}\".format(multiprocessing.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = NewsData(args.dataset_name, args.tokenizer_name,\n",
    "                batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                pin_memory=(device==\"cuda\"), debug=args.debug_data,\n",
    "                debug_data_len=args.debug_data_len, max_seq_len=args.max_seq_len, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VAE_Decoder_RobertaForCausalLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'VAE_Decoder_Roberta.VAE_Decoder_RobertaModel'> and <class 'transformers.modeling_roberta.RobertaModel'> are not equal. In this case make sure that all encoder weights are correctly initialized. \n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
      "Loading VAE_model, optimizer and scheduler from /home/cbarkhof/code-thesis/NewsVAE/Runs/18NOV-BETA-VAE-run-2020-11-18-12:36:55/checkpoint-50000.pth\n",
      "first removing module string from checkpoint\n",
      "Checkpoint global_step: 50000, epoch: 33, best_valid_loss: 3.116105151176453\n",
      "Loading VAE_model, optimizer and scheduler from /home/cbarkhof/code-thesis/NewsVAE/Runs/18NOV-MMD-VAE-run-2020-11-18-12:36:55/checkpoint-50000.pth\n",
      "first removing module string from checkpoint\n",
      "Checkpoint global_step: 50000, epoch: 33, best_valid_loss: 2.233636903762817\n",
      "Loading VAE_model, optimizer and scheduler from /home/cbarkhof/code-thesis/NewsVAE/Runs/23NOV-AUTOENCODER-run-2020-11-23-18:36:12/checkpoint-50000.pth\n",
      "first removing module string from checkpoint\n",
      "Checkpoint global_step: 50000, epoch: 33, best_valid_loss: 1.0603568315505982\n"
     ]
    }
   ],
   "source": [
    "# Get model architecture\n",
    "VAE_model = EncoderDecoderShareVAE(args, args.base_checkpoint_name, do_tie_weights=args.do_tie_weights).to(device)\n",
    "\n",
    "# # Load weights\n",
    "beta_vae_path = \"/home/cbarkhof/code-thesis/NewsVAE/Runs/18NOV-BETA-VAE-run-2020-11-18-12:36:55/checkpoint-50000.pth\"\n",
    "mmd_vae_path = \"/home/cbarkhof/code-thesis/NewsVAE/Runs/18NOV-MMD-VAE-run-2020-11-18-12:36:55/checkpoint-50000.pth\"\n",
    "ae_path = \"/home/cbarkhof/code-thesis/NewsVAE/Runs/23NOV-AUTOENCODER-run-2020-11-23-18:36:12/checkpoint-50000.pth\"\n",
    "\n",
    "# Need to make a deepcopy otherwise the weights are assigned to the original VAE_model which leads to confusing results :O\n",
    "_, _, beta_vae_model, _, _, _, _ = load_from_checkpoint(copy.deepcopy(VAE_model), args, path=beta_vae_path)\n",
    "_, _, mmd_vae_model, _, _, _, _ = load_from_checkpoint(copy.deepcopy(VAE_model), args, path=mmd_vae_path)\n",
    "_, _, ae_model, _, _, _, _ = load_from_checkpoint(copy.deepcopy(VAE_model), args, path=ae_path)\n",
    "\n",
    "del VAE_model\n",
    "beta_vae_model.eval(); mmd_vae_model.eval(); ae_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_prior(latent_size=768, n_samples=8):\n",
    "    loc = torch.zeros(latent_size, device='cuda:0')\n",
    "    scale = torch.ones(latent_size, device='cuda:0')\n",
    "    prior_dist = torch.distributions.normal.Normal(loc, scale)\n",
    "    samples = prior_dist.sample((n_samples,))\n",
    "    return samples\n",
    "    \n",
    "def sample_text(model, tokenizer, args, n_samples=8, max_seq_len=64, nucleus_sampling=True):\n",
    "    with torch.no_grad():\n",
    "        latent_z = sample_from_prior(model.latent_size, n_samples=n_samples)\n",
    "        generated = auto_regressive_decode(model, latent_z, tokenizer, args, max_seq_len=max_seq_len, nucleus_sampling=nucleus_sampling)\n",
    "        generated_text = batch_decode(generated, tokenizer)\n",
    "        return generated_text\n",
    "\n",
    "def batch_decode(batch_of_samples, tokenizer):    \n",
    "    return [tokenizer.decode(a.tolist()) for a in batch_of_samples]\n",
    "\n",
    "def auto_regressive_decode(model, latent_z, tokenizer, args, max_seq_len=32, nucleus_sampling=False, \n",
    "                           temperature=1.0, top_k=0, top_p=0.9):\n",
    "    batch_size = latent_z.shape[0]\n",
    "\n",
    "    # Add <s> and </s>\n",
    "    generated_so_far = torch.tensor([[data.tokenizer.bos_token_id, data.tokenizer.eos_token_id] for _ in range(batch_size)])\n",
    "    generated_so_far = generated_so_far.cuda(0)\n",
    "\n",
    "    for i in range(max_seq_len):        \n",
    "        # Forward the decoder\n",
    "        decoder_outs = model.decoder(input_ids=generated_so_far, attention_mask=None,\n",
    "                                    latent_z=latent_z, labels=None,\n",
    "                                    add_latent_via_embeddings=args.add_latent_via_embeddings,\n",
    "                                    add_latent_via_memory=args.add_latent_via_memory,\n",
    "                                    return_cross_entropy=False, return_predictions=True,\n",
    "                                    return_exact_match_acc=False)\n",
    "\n",
    "        if nucleus_sampling:\n",
    "            # The forward of the decoder already cuts of the prediction for the last token\n",
    "            logits = decoder_outs[\"logits\"][:, -1, :]\n",
    "\n",
    "            # Temperature (higher temperature => more likely to sample low probability tokens)\n",
    "            if temperature != 1.0:\n",
    "                scores = scores / temperature\n",
    "\n",
    "            # Top-p/top-k filtering\n",
    "            next_token_logscores = top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
    "\n",
    "            # Sample\n",
    "            probs = F.softmax(next_token_logscores, dim=-1)\n",
    "            new_preds = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "        else:\n",
    "            new_preds = decoder_outs['predictions'][:, -1] # argmax predictions\n",
    "\n",
    "        generated_so_far = torch.cat((generated_so_far[:, :-1], new_preds.unsqueeze(1), generated_so_far[:, -1].unsqueeze(1)), dim=1)\n",
    "    return generated_so_far\n",
    "\n",
    "def encode(model, input_batch, deterministic=False):\n",
    "    encoder_outs = model.encoder(input_ids=input_batch['input_ids'], attention_mask=input_batch['attention_mask'])\n",
    "    latent_z, _, _ = model.connect_encoder_decoder(encoder_outs.pooler_output, deterministic=deterministic)\n",
    "    \n",
    "    return latent_z\n",
    "\n",
    "def encode_auto_regressive_decode(model, input_batch, tokenizer, args, max_seq_len=64, nucleus_sampling=True):\n",
    "    with torch.no_grad():\n",
    "        latent_z = encode(model, input_batch)\n",
    "        generated = auto_regressive_decode(model, latent_z, tokenizer, args, max_seq_len=max_seq_len, nucleus_sampling=nucleus_sampling)\n",
    "        generated_text = batch_decode(generated, tokenizer)\n",
    "        \n",
    "        return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_batches = 5\n",
    "# results = {'aaNotionColumn': [f\"aaNotionValue_{i}\" for i in range(max_batches * args.batch_size)],\n",
    "#            'original': [],\n",
    "#            'mmd-vae': [],\n",
    "#            'beta-vae': [],\n",
    "#            'ae-model':[],\n",
    "#           }\n",
    "\n",
    "\n",
    "# for batch_i, input_batch in enumerate(data.val_dataloader(shuffle=True)):\n",
    "#     print(f\"Batch {batch_i}\", end=\"\\r\")\n",
    "#     input_batch = transfer_batch_to_device(input_batch, 0)\n",
    "#     original_text = batch_decode(input_batch['input_ids'], data.tokenizer)\n",
    "#     results['original'].extend(original_text)\n",
    "    \n",
    "#     for model, model_name in zip([mmd_vae_model, beta_vae_model, ae_model], ['mmd-vae', 'beta-vae', 'ae-model']):\n",
    "#         generated_text = encode_auto_regressive_decode(model, input_batch, data.tokenizer, \n",
    "#                                                        args, max_seq_len=64, nucleus_sampling=True)\n",
    "#         results[model_name].extend(generated_text)\n",
    "\n",
    "#     if batch_i + 1 == max_batches: break\n",
    "        \n",
    "# df = pd.DataFrame(results)\n",
    "# df.to_csv('text_reconstructions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample\n",
    "# n_samples = 1000\n",
    "# batch_size = 10\n",
    "\n",
    "# prior_samples = sample_from_prior(latent_size=768, n_samples=n_samples)\n",
    "\n",
    "# encoded_samples_beta = []\n",
    "# encoded_samples_mmd = []\n",
    "# encoded_samples_ae = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     assert n_samples % batch_size == 0, \"n_samples must be exactly divisible by the batch size!\"\n",
    "#     max_batches = int(n_samples / batch_size)\n",
    "    \n",
    "#     print(\"max_batches:\", max_batches)\n",
    "    \n",
    "#     for batch_i, input_batch in enumerate(data.val_dataloader(shuffle=True, batch_size=batch_size)):\n",
    "#         if batch_i % 10 == 0: print(\"Batch {:2d}/{}\".format(batch_i, max_batches), end='\\r')\n",
    "\n",
    "#         input_batch = transfer_batch_to_device(input_batch, 0)\n",
    "        \n",
    "#         encoded_samples_beta.append(encode(beta_vae_model, input_batch, deterministic=False))\n",
    "#         encoded_samples_mmd.append(encode(mmd_vae_model, input_batch, deterministic=False))\n",
    "#         encoded_samples_ae.append(encode(ae_model, input_batch, deterministic=False))\n",
    "\n",
    "#         if batch_i + 1 == max_batches: break\n",
    "        \n",
    "# encoded_samples_beta = torch.cat(encoded_samples_beta)\n",
    "# encoded_samples_mmd = torch.cat(encoded_samples_mmd)\n",
    "# encoded_samples_ae = torch.cat(encoded_samples_ae)\n",
    "\n",
    "# print(prior_samples.shape, encoded_samples_beta.shape, encoded_samples_mmd.shape, encoded_samples_ae.shape)\n",
    "\n",
    "# # Reduce dimensionality PCA -> TSNE\n",
    "# all_samples = torch.cat((prior_samples, encoded_samples_beta, encoded_samples_mmd, encoded_samples_ae))\n",
    "# all_samples_pca = PCA(n_components=50).fit_transform(all_samples.cpu().numpy())\n",
    "# all_samples_tsne_2dim = TSNE(n_components=2, n_iter=500, perplexity=20).fit_transform(all_samples_pca)\n",
    "\n",
    "# # Plot\n",
    "# plt.scatter(all_samples_tsne_2dim[:1000, 0], all_samples_tsne_2dim[:1000, 1], label='Prior', alpha=0.3, color='green')\n",
    "# plt.scatter(all_samples_tsne_2dim[1000:2000, 0], all_samples_tsne_2dim[1000:2000, 1], label='Encoded Beta-VAE', alpha=0.3, color='blue')\n",
    "# plt.scatter(all_samples_tsne_2dim[2000:3000, 0], all_samples_tsne_2dim[2000:3000, 1], label='Encoded MMD-VAE', alpha=0.3, color='pink')\n",
    "# plt.scatter(all_samples_tsne_2dim[3000:, 0], all_samples_tsne_2dim[3000:, 1], label='Encoded AE', alpha=0.3, color='orange')\n",
    "# plt.legend()\n",
    "# plt.savefig(\"latent_space_plt.png\", dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples from: mmd-vae\n",
      "0\n",
      "<s>Traits forfeishing in toing not in to to to by being in au in in was was noting in to in when to to Rebecca di didnne has the ending to being ownership in the Juan Juan is hasu has been voted Elizabeth has Peter has to the the the Kenne to the the</s></s></s>\n",
      "\n",
      "1\n",
      "<s>By and and and and and Rick and. combined.. Shane Shane Shane.'s Sunday Thursday. Wednesday Thursday Wednesday. Monday Monday Wednesday. Sunday Thursday Wednesday Wednesday Thursday. Mick.. Tom. He Foley.. Wednesday. Wednesday. Duffy. Tony.. Friday has has...</s>. Rey has</s></s></s>\n",
      "\n",
      "2\n",
      "<s> monthsil,,,il-,il,il-il----az,ilil,il,ililacheache-ilil world (:: (:----to::, to to for to:.:,,..- in to.-</s></s></s></s>\n",
      "\n",
      "3\n",
      "<s>LLE David David \" -- AL D \"\" \"2 that as a David would could would take alers he if as he had had had a a having had that a had'd an a a. an had made an an.. an. the that the had.. a.. had a.</s></s></s>\n",
      "\n",
      "4\n",
      "<s> In-�-es,As-ysys--giesys)--igys:,. and-ies�,-ies), – and, and?.,,, and-w-�, and�.</s>,� and and.,�,,, and</s></s></s>\n",
      "\n",
      "5\n",
      "<s> Aviation outside his association's's has his AW268 membership membership approval's attached to his head-union that regards his head-fire his holiday of the his title to)-free approval to-out his-owned anowned''���ari.US.his: holiday.IGHTS-owned,</s></s></s>\n",
      "\n",
      "6\n",
      "<s>(gewew---the--t/-thethe-mmm. business-ains the links... service service.............. service......... service......</s></s></s></s>\n",
      "\n",
      "7\n",
      "<s>TheousousousousThe andous and has the,a has for to the theaous and has and the to and Maa the thes the, over the to, the a, on Saturday on earlier during several groups, on days to while on attacks, against on groups on, verses to</s></s></s>\n",
      "\n",
      "8\n",
      "<s>(ingiana)'ni (ani)). (13)))))inging. (())))(( ())((.)( (())..)That. that...ThatThat That. that. that that. that..</s></s></s>\n",
      "\n",
      "9\n",
      "<s>..  Is. Is...,?.., Is...................,.,.. ...... Take.. Okay Take. Love. It Is. Love. For.</s></s></s>\n",
      "\n",
      "------------------------------\n",
      "Samples from: beta-vae\n",
      "0\n",
      "<s>By. Daily Mail Reporter. PUBLISHED:. 03:17 EST, 15 May 2013. |. UPDATED:. 07:39 EST, 15 May 2013. The birth of new triplets could be nearly as distant as every year after the man who lit the world's largest firework died</s> Angel</s>\n",
      "\n",
      "1\n",
      "<s>By. Leon Watson. PUBLISHED:. 07:49 EST, 15 July 2013. |. UPDATED:. 11:21 EST, 15 July 2013. One of the world's biggest supermarket chains, Nando's, unveiled on Monday its logo with just 25 smiling customers and a whole front</s>.</s>\n",
      "\n",
      "2\n",
      "<s>(CNN)  -- Ten Turkish people held by al Qaeda were released Tuesday, a day after activists accused the militants of \"engaging in violent crimes against our people\" -- and raising fears of a new crackdown on the government. \"The human trafficking demands a minimum as high as 15 grams of cocaine.\" \"</s></s></s>\n",
      "\n",
      "3\n",
      "<s>By. Sam Webb. A kangaroo who lived in a Siberian zoo for more than two decades has been released from the Siberian. curator who tweeted she was 'Taken' by. \"Used the propane tank' which Ms Smith had been flying in. the zoo has been renamed Lake Kemsatyr</s></s></s>\n",
      "\n",
      "4\n",
      "<s>LONDON, England (CNN) -- If any question about climate change shifts into the real world, just look at the prices of green milk. U.S. dairy cows cross the border in a livestock farm in Manitoba, Canada. How green milk prices change on the spot can only be described as generous.</s></s></s>\n",
      "\n",
      "5\n",
      "<s>(CNN) -- Rolling Stone magazine is offering to the editor of Rolling Stone its confidential conversations with NSA leaker Edward Snowden that were broadcast by a former CIA officer. The video was apparently from the summer of 2010, when Snowden was to pick up the phone from his nanny, who was calling to take him</s></s></s>\n",
      "\n",
      "6\n",
      "<s>By. Mark Duell. PUBLISHED:. 11:12 EST, 15 August 2013. |. UPDATED:. 11:17 EST, 15 August 2013. A shopper faces involuntary manslaughter charges over the death of a 19-year-old nurse whose sub-continent cut off her</s> '</s>\n",
      "\n",
      "7\n",
      "<s>(CNN) -- At the crossroads of European and American politics, Egypt's alleged financial fraud is a source of intrigue for investors, analysts and opposition lawmakers alike. Sajida ElBaradei said it is \"a question that lies in the depths of the present crisis and now lies with every person who</s></s></s>\n",
      "\n",
      "8\n",
      "<s>By. Daily Mail Reporter. PUBLISHED:. 03:38 EST, 4 August 2012. |. UPDATED:. 14:10 EST, 5 August 2012. The vice principal of TransCanada’s passenger rail line said he would be investigating a possible link to the dramatic increase in the</s>.</s>\n",
      "\n",
      "9\n",
      "<s>By. Rachel Quigley. PUBLISHED:. 08:42 EST, 11 July 2012. |. UPDATED:. 10:50 EST, 11 July 2012. Syrian villagers rescued a street cleaner from a house and she used a weapon to trap her assailant in an alley so she could escape</s>:</s>\n",
      "\n",
      "------------------------------\n",
      "Samples from: ae-model\n",
      "0\n",
      "<s>sim not then that that another but not. one of that who said the country's which which when with a period's which when. time. as a., which who which have have a time�z's. when�ies for a series' by.. that.'s. an-- has</s></s></s>\n",
      "\n",
      "1\n",
      "<s>A220.220IT:. C::. $--245, positive-cent. fat, t is. You, fat is at at, A is leader is the president to leader at at at a--------ter. A-co's has sits a at</s></s></s>\n",
      "\n",
      "2\n",
      "<s>kekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekekeke</s>\n",
      "\n",
      "3\n",
      "<s>WASHINGTON (CNN)))))))))))) (10) 1) in Mayon 1 of the20). 9:4 of the 2010. Duringon 710. critical on of others to others. Whileues encouraged on the leaders in the efforts of the others, last</s> The</s>\n",
      "\n",
      "4\n",
      "<s>GR,SW,SW,BR-KN, to to-evev approved,, police as:,, all to to of;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;</s></s></s>\n",
      "\n",
      "5\n",
      "<s>CLIAED KarlOGEE HARTENHOGERS FOR CECKE FEDENEHEYE FOR CCHCHCHEE for:: IANEER JUH ( for ICHSCHE. she has offered to to being for the three that they have</s></s></s>\n",
      "\n",
      "6\n",
      "<s>By#aminaminte. -- 15). more to to about. Aad continues continue to thinking. A To. In Ato Report. A Name-Ccusion. Aika. A tellsntto. A)Mika. A***.tad. Cricacyeayed.].</s>\n",
      "\n",
      "7\n",
      "<s> Alto. Reading,, and.</s>ow, the andow, of the place of the and \"\",\" of of itself,... \". --,.. .�..</s>...�,,... Its,,.</s>,, The.</s></s></s></s></s>\n",
      "\n",
      "8\n",
      "<s>Uill ( ( ( (win ( ($ ($ ($ ($ (R--/( (69) 8) ((Uuary) (win, 72:- Wilson) their relative name. he-man (Theuary) he is new to the the – Friday. the theman. they announced</s></s></s>\n",
      "\n",
      "9\n",
      "<s> lastyawn hasouted alacedaced on a spot and of a button and andied five and and sixemiedied five.ies said.ies said.our said.ied five.ies.ied itiesied some of five-iesies. It said in certain that certain publicies that</s></s></s>\n",
      "\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaNotionColumn</th>\n",
       "      <th>mmd-vae</th>\n",
       "      <th>beta-vae</th>\n",
       "      <th>ae-model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaNotionValue_0</td>\n",
       "      <td>&lt;s&gt;Traits forfeishing in toing not in to to to...</td>\n",
       "      <td>&lt;s&gt;By. Daily Mail Reporter. PUBLISHED:. 03:17 ...</td>\n",
       "      <td>&lt;s&gt;sim not then that that another but not. one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaNotionValue_1</td>\n",
       "      <td>&lt;s&gt;By and and and and and Rick and. combined.....</td>\n",
       "      <td>&lt;s&gt;By. Leon Watson. PUBLISHED:. 07:49 EST, 15 ...</td>\n",
       "      <td>&lt;s&gt;A220.220IT:. C::. $--245, positive-cent. fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaNotionValue_2</td>\n",
       "      <td>&lt;s&gt; monthsil,,,il-,il,il-il----az,ilil,il,ilil...</td>\n",
       "      <td>&lt;s&gt;(CNN)  -- Ten Turkish people held by al Qae...</td>\n",
       "      <td>&lt;s&gt;kekekekekekekekekekekekekekekekekekekekekek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaNotionValue_3</td>\n",
       "      <td>&lt;s&gt;LLE David David \" -- AL D \"\" \"2 that as a D...</td>\n",
       "      <td>&lt;s&gt;By. Sam Webb. A kangaroo who lived in a Sib...</td>\n",
       "      <td>&lt;s&gt;WASHINGTON (CNN)))))))))))) (10) 1) in Mayo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaNotionValue_4</td>\n",
       "      <td>&lt;s&gt; In-�-es,As-ysys--giesys)--igys:,. and-ies�...</td>\n",
       "      <td>&lt;s&gt;LONDON, England (CNN) -- If any question ab...</td>\n",
       "      <td>&lt;s&gt;GR,SW,SW,BR-KN, to to-evev approved,, polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aaNotionValue_5</td>\n",
       "      <td>&lt;s&gt; Aviation outside his association's's has h...</td>\n",
       "      <td>&lt;s&gt;(CNN) -- Rolling Stone magazine is offering...</td>\n",
       "      <td>&lt;s&gt;CLIAED KarlOGEE HARTENHOGERS FOR CECKE FEDE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aaNotionValue_6</td>\n",
       "      <td>&lt;s&gt;(gewew---the--t/-thethe-mmm. business-ains ...</td>\n",
       "      <td>&lt;s&gt;By. Mark Duell. PUBLISHED:. 11:12 EST, 15 A...</td>\n",
       "      <td>&lt;s&gt;By#aminaminte. -- 15). more to to about. Aa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aaNotionValue_7</td>\n",
       "      <td>&lt;s&gt;TheousousousousThe andous and has the,a has...</td>\n",
       "      <td>&lt;s&gt;(CNN) -- At the crossroads of European and ...</td>\n",
       "      <td>&lt;s&gt; Alto. Reading,, and.&lt;/s&gt;ow, the andow, of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aaNotionValue_8</td>\n",
       "      <td>&lt;s&gt;(ingiana)'ni (ani)). (13)))))inging. (())))...</td>\n",
       "      <td>&lt;s&gt;By. Daily Mail Reporter. PUBLISHED:. 03:38 ...</td>\n",
       "      <td>&lt;s&gt;Uill ( ( ( (win ( ($ ($ ($ ($ (R--/( (69) 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aaNotionValue_9</td>\n",
       "      <td>&lt;s&gt;..  Is. Is...,?.., Is...................,.,...</td>\n",
       "      <td>&lt;s&gt;By. Rachel Quigley. PUBLISHED:. 08:42 EST, ...</td>\n",
       "      <td>&lt;s&gt; lastyawn hasouted alacedaced on a spot and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    aaNotionColumn                                            mmd-vae  \\\n",
       "0  aaNotionValue_0  <s>Traits forfeishing in toing not in to to to...   \n",
       "1  aaNotionValue_1  <s>By and and and and and Rick and. combined.....   \n",
       "2  aaNotionValue_2  <s> monthsil,,,il-,il,il-il----az,ilil,il,ilil...   \n",
       "3  aaNotionValue_3  <s>LLE David David \" -- AL D \"\" \"2 that as a D...   \n",
       "4  aaNotionValue_4  <s> In-�-es,As-ysys--giesys)--igys:,. and-ies�...   \n",
       "5  aaNotionValue_5  <s> Aviation outside his association's's has h...   \n",
       "6  aaNotionValue_6  <s>(gewew---the--t/-thethe-mmm. business-ains ...   \n",
       "7  aaNotionValue_7  <s>TheousousousousThe andous and has the,a has...   \n",
       "8  aaNotionValue_8  <s>(ingiana)'ni (ani)). (13)))))inging. (())))...   \n",
       "9  aaNotionValue_9  <s>..  Is. Is...,?.., Is...................,.,...   \n",
       "\n",
       "                                            beta-vae  \\\n",
       "0  <s>By. Daily Mail Reporter. PUBLISHED:. 03:17 ...   \n",
       "1  <s>By. Leon Watson. PUBLISHED:. 07:49 EST, 15 ...   \n",
       "2  <s>(CNN)  -- Ten Turkish people held by al Qae...   \n",
       "3  <s>By. Sam Webb. A kangaroo who lived in a Sib...   \n",
       "4  <s>LONDON, England (CNN) -- If any question ab...   \n",
       "5  <s>(CNN) -- Rolling Stone magazine is offering...   \n",
       "6  <s>By. Mark Duell. PUBLISHED:. 11:12 EST, 15 A...   \n",
       "7  <s>(CNN) -- At the crossroads of European and ...   \n",
       "8  <s>By. Daily Mail Reporter. PUBLISHED:. 03:38 ...   \n",
       "9  <s>By. Rachel Quigley. PUBLISHED:. 08:42 EST, ...   \n",
       "\n",
       "                                            ae-model  \n",
       "0  <s>sim not then that that another but not. one...  \n",
       "1  <s>A220.220IT:. C::. $--245, positive-cent. fa...  \n",
       "2  <s>kekekekekekekekekekekekekekekekekekekekekek...  \n",
       "3  <s>WASHINGTON (CNN)))))))))))) (10) 1) in Mayo...  \n",
       "4  <s>GR,SW,SW,BR-KN, to to-evev approved,, polic...  \n",
       "5  <s>CLIAED KarlOGEE HARTENHOGERS FOR CECKE FEDE...  \n",
       "6  <s>By#aminaminte. -- 15). more to to about. Aa...  \n",
       "7  <s> Alto. Reading,, and.</s>ow, the andow, of ...  \n",
       "8  <s>Uill ( ( ( (win ( ($ ($ ($ ($ (R--/( (69) 8...  \n",
       "9  <s> lastyawn hasouted alacedaced on a spot and...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 10\n",
    "sampling_results = {'aaNotionColumn': [f\"aaNotionValue_{i}\" for i in range(n_samples)]}\n",
    "\n",
    "for model, name in zip([mmd_vae_model, beta_vae_model, ae_model], ['mmd-vae', 'beta-vae', 'ae-model']):\n",
    "    print('Samples from:', name)\n",
    "    gen_text = sample_text(model, data.tokenizer, args, n_samples=n_samples, max_seq_len=64, nucleus_sampling=True)\n",
    "    sampling_results[name] = gen_text\n",
    "#     for i, t in enumerate(gen_text):\n",
    "#         print(i)\n",
    "#         print(t)\n",
    "#         print()\n",
    "#     print(\"-\"*30)\n",
    "                    \n",
    "df = pd.DataFrame(sampling_results)\n",
    "display(df)\n",
    "df.to_csv('sampling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".to_csv(\"sampling.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "thesisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
