{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Jupyter server on LISA pls.\n"
     ]
    }
   ],
   "source": [
    "from EncoderDecoderShareVAE import EncoderDecoderShareVAE\n",
    "import NewsVAEArguments\n",
    "from transformers import RobertaTokenizer\n",
    "import torch\n",
    "from NewsData import NewsData\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Check if on server\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Start Jupyter server on LISA pls.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {}\n",
    "\n",
    "# Get data\n",
    "data = NewsData(args.dataset_name, args.tokenizer_name,\n",
    "                batch_size=args.batch_size, num_workers=args.num_workers,\n",
    "                pin_memory=True, debug=args.debug_data,\n",
    "                debug_data_len=args.debug_data_len, max_seq_len=args.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.ddp = True\n",
    "for phase in ['train', 'validation']:\n",
    "    if args.ddp:\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(data.datasets[phase], rank=0,\n",
    "                                                                  num_replicas=1, shuffle=True)\n",
    "        # With distributed sampling, shuffle must be false\n",
    "        loaders[phase] = DataLoader(data.datasets[phase], batch_size=args.batch_size,\n",
    "                                    sampler=sampler, shuffle=False, pin_memory=False,\n",
    "                                    num_workers=args.num_workers, collate_fn=data.collate_fn)\n",
    "    else:\n",
    "        # Without distributed sampling\n",
    "        loaders[phase] = DataLoader(data.datasets[phase], batch_size=args.batch_size,\n",
    "                                    shuffle=True, pin_memory=True,\n",
    "                                    num_workers=args.num_workers, collate_fn=data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in range(5):\n",
    "    print(\"--> round\", x)\n",
    "    print(len(loaders['train']))\n",
    "#     for batch_i, batch in enumerate(loaders['train']):\n",
    "# #         if batch_i == 3:\n",
    "# #             break\n",
    "#         print(batch['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "SOME IMPORTANT ARGUMENTS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAX SEQ LEN: 64\n",
      "OBJECTIVE: beta-vae\n",
      "BETA-VAE OBJECTIVE with KL ANNEALING:\n",
      "KL-ANNEALING (step per effective batch size): True\n",
      "HINGE TARGET KL: 0.5\n",
      "------------------------------\n",
      "N_GPUS: 0\n",
      "DDP: False\n",
      "BATCH SIZE: 32\n",
      "GRADIENT ACCUMULATION (N BATCHES): 1\n",
      "EFFECTIVE BATCHSIZE PER GRAD STEP: 0\n",
      "------------------------------\n",
      "LR: 0.05\n",
      "TIE WEIGHTS: True\n",
      "GRAD CHECKPOINT: False\n",
      "------------------------------\n",
      "CHECKPOINTING: False\n",
      "LOGGING: True\n",
      "RUN PREFIX: TEST\n",
      "------------------------------\n",
      "TRAIN (GLOBAL) STEPS: 50000\n",
      "TRAIN EPOCH LEN: 2000\n",
      "VALID EPOCH LEN: 100\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "args = NewsVAEArguments.preprare_parser(jupyter=True)\n",
    "args.ddp = False\n",
    "args.n_gpus = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of VAE_Decoder_RobertaForCausalLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'VAE_Decoder_Roberta.VAE_Decoder_RobertaModel'> and <class 'transformers.modeling_roberta.RobertaModel'> are not equal. In this case make sure that all encoder weights are correctly initialized. \n",
      "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
     ]
    }
   ],
   "source": [
    "VAE_model = EncoderDecoderShareVAE(args, args.base_checkpoint_name, do_tie_weights=args.do_tie_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1112 12:07:55.105442 4518768064 filelock.py:274] Lock 140544657157648 acquired on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1112 12:07:55.236371 4518768064 filelock.py:318] Lock 140544657157648 released on /Users/claartje/.cache/huggingface/datasets/4b801baa55da8559101ff966972c8ee2ebc8962c04d7c12172781053e957de7a.1bf1bb5abb0006b64eb0c53264061ddb85f91fa7f9deec04a4de38a4c09a0ec0.py.lock\n",
      "I1112 12:07:55.649162 4518768064 filelock.py:274] Lock 140544655829648 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1112 12:07:55.652176 4518768064 filelock.py:318] Lock 140544655829648 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "I1112 12:07:55.653185 4518768064 filelock.py:274] Lock 140544657157144 acquired on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "Reusing dataset cnn_dailymail (/Users/claartje/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n",
      "I1112 12:07:55.655190 4518768064 filelock.py:318] Lock 140544657157144 released on /Users/claartje/.cache/huggingface/datasets/_Users_claartje_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602.lock\n",
      "Loading cached processed dataset at /Users/claartje/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602/cache-46bdeab012bb2377.arrow\n"
     ]
    }
   ],
   "source": [
    "def convert_to_features(data_batch, tokenizer=None, args=None):\n",
    "    encoded_batch = tokenizer(data_batch['article'], truncation=True, max_length=args.max_seq_len, padding=True)\n",
    "    encoded_batch['article'] = [a for a in data_batch['article']]\n",
    "    encoded_batch['id'] = [i for i in data_batch['id']]\n",
    "    return encoded_batch\n",
    "\n",
    "dataset_validation = load_dataset('cnn_dailymail', name='3.0.0', ignore_verifications=True, split='validation[:1000]')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "encoded_dataset_validation = dataset_validation.map(partial(convert_to_features, tokenizer=tokenizer, args=args), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_batch_ids(low, high, size):\n",
    "    random_ints = []\n",
    "    while len(random_ints) != size:\n",
    "        r = np.random.randint(low, high)\n",
    "        if r not in random_ints:\n",
    "            random_ints.append(r)\n",
    "    return list(random_ints)\n",
    "\n",
    "def get_random_batch(dataset, batchsize=32):\n",
    "    ids = get_random_batch_ids(0, len(dataset), batchsize)\n",
    "    attention_mask_batch = torch.LongTensor(dataset[ids]['attention_mask'])\n",
    "    input_ids_batch = torch.LongTensor(dataset[ids]['input_ids'])\n",
    "    input_batch = {'attention_mask': attention_mask_batch, 'input_ids':input_ids_batch}\n",
    "    return dataset[ids], input_batch\n",
    "\n",
    "batch_all, input_batch = get_random_batch(encoded_dataset_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = VAE_model(input_ids=input_batch['input_ids'],\n",
    "                            attention_mask=input_batch['attention_mask'],\n",
    "                            beta=1.0, args=args, return_predictions=True)\n",
    "    predictions['total_loss'] = predictions['total_loss'].item() # detach the graph\n",
    "    \n",
    "    # Get predicted ids\n",
    "    predictions['predictions'] = torch.nn.functional.softmax(predictions['logits'].view(-1, predictions['logits'].shape[-1]), dim=-1).argmax(dim=1)\n",
    "    predictions['predictions'] = predictions['predictions'].reshape(predictions['logits'].shape[0], predictions['logits'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s></s></s></s></s></s></s></s></s>/</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> weight</s></s>,</s></s></s></s>mm</s></s></s></s></s></s></s></s></s></s>ont>> weight,</s>, weight</s>/,</s></s>,</s></s></s>',\n",
       " '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>ing</s></s></s></s></s></s> play Video</s></s> video trade</s></s></s></s></s> public video public</s></s></s></s></s></s></s></s></s></s></s></s></s>.</s></s></s> dad dad dad dad. Video</s> local</s></s></s>',\n",
       " '<s></s></s></s></s>er and and and and and and and and and and and and and and and and and and and andp andig ando and and and and and and and and and and andpand and and andp and andp andp and and and and and andp andand and and',\n",
       " '<s></s></s> uping in up</s> up up Americans up up up up jack up up over up up up plus super super super Peak up up super super up plus super super New New combined super up up New New Peak Peak super super super super up super super super super super super super super super super super Plus super super',\n",
       " '<s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>atal</s>alate</s></s></s></s></s> the</s>ate the</s></s> the</s></s></s></s> and</s> play play pan play</s> pan play draw play play play play.</s> play</s></s> play',\n",
       " '<s></s></s></s></s></s></s></s> and</s></s></s></s> 72 administration policy</s> the policy the confidentiality retail</s> partnering policy strategy retail policy 72 confidentiality confidentiality confidentiality policy policy confidentiality policy policy policy confidentiality confidentiality policy policy</s> retail confidentiality policies confidentiality confidentiality confidentiality closure confidentiality boundaries confidentiality 72 confidentiality confidentiality confidentiality policy policy confidentiality confidentiality confidentiality confidentiality</s>',\n",
       " '<s></s></s></s></s></s></s> Share</s></s></s> perform</s></s></s></s> live</s></s> and</s> live forward ~</s></s></s> Oh home ~ ~ ~ ~</s> ~ ~ ~ ~ plays ~ ~</s> ~ ~</s> hope hope</s> ~</s></s> for hope ~ ~</s> Oh hope ~ hope</s> ~ ~</s>',\n",
       " '<s></s></s></s></s> to,,</s> to</s>, it. the police and to,</s> common</s> company territory</s> company common common company territory, primeo co and prime prime prime primeVA common common company prime common prime common prime common prime prime prime prime common prime say common common territory prime prime say prime territory',\n",
       " '<s></s></s></s></s>- one</s> will will be will money will real pa real</s> will pa will</s> will will real will</s> will par will will will par war will -- ParkeraPenn -- will par from Parker will Penn</s> Penn even par par</s>ount</s> will Penn Penn-</s>- war will will Penn',\n",
       " '<s></s></s>:</s></s></s></s></s></s></s></s></s></s></s></s></s></s>.</s></s></s></s></s></s>adeav</s></s>.</s></s></s> theav</s></s> $ and:</s></s>av</s></s></s></s></s> of. theo de Village,</s> of</s></s></s></s></s></s></s>',\n",
       " '<s></s> and and and medical and killing blank and and and and and and and and and and and and and and and and and and and and and and stop and stop and and and and and stop stop stop stop stop of and and and and and stop and stop and and and and and stop medical and and stop money',\n",
       " '<s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>?</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>',\n",
       " '</s></s>CNNark</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>ShareShare</s></s></s></s></s></s></s></s></s></s></s> share</s> share</s>Share Linkarkark Photo auto</s> vote</s>',\n",
       " '<s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> key</s></s> Emailstylestyle television key</s> style style</s></s></s></s></s></s></s></s></s></s></s></s></s> style key</s></s></s></s></s></s> power</s></s></s></s></s></s>style</s></s> super</s></s>',\n",
       " '</s></s></s></s></s>::::</s></s></s></s></s></s></s></s></s></s></s></s>o</s> crew crew crew crew crew crew crew crew crew crew crew crew crew crew crew crew crew</s> crew</s></s></s></s> crew crew crew</s> crew crew crew crew crew crew crew crew crew crew crew crew crew</s>',\n",
       " '<s></s></s></s></s></s> and</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> administrative</s> administrative</s></s></s> status national plan administrative</s></s></s></s> final year local local final local local local lands local post final local final local local local local</s>',\n",
       " '</s></s></s></s></s></s></s> and</s></s></s></s></s></s></s></s></s></s> and salt</s>moon</s></s></s></s></s>moon salt salt</s></s></s></s></s></s> saltmoonmoon</s></s></s></s></s> launch salt salt moonmoonmoonmoon saltfill</s>moontowntravel</s>moon...moon</s>travel</s>',\n",
       " '</s></s></s></s></s></s></s></s></s>ng the content. x., x ph x ph teacher ph</s></s> x x x</s></s></s> lo lo lo lo lo,,, lo</s> lo lo the the lo lo the</s> the</s> the</s></s>ly. Ho lo, lo lo lo lo lo</s>',\n",
       " '<s></s><s></s><s></s>: below below below</s>....</s>:</s>.</s>. level 9 53 and - -, one the a make a and a a a</s></s> Episode. it a to level the the</s> a the first level to the low to level starting a high-. a a',\n",
       " '<s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>Share</s></s></s> social</s></s></s></s></s></s></s> social Social social social Party State social</s>',\n",
       " '<s>year--year oil day oil day- oil next-</s>- oil day day day day</s>- day plan day day gas day day plan day day oil day day day day day day day day day day day day day day day day day day day, day day day day day day, day day day day',\n",
       " '<s>advertisementAnalysis</s>::</s></s></s></s>:</s> news</s></s></s></s></s></s>:</s></s> fire Chinese leader</s>:</s></s></s></s> full Russianed</s></s></s></s></s> full</s> no no full</s></s></s></s></s></s> hard mass direct full mass full full</s> full re full be assisted re',\n",
       " '</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>.</s></s></s></s></s></s>,, and</s></s></s></s></s></s></s></s></s></s>..</s> be</s></s></s>, and</s></s></s></s></s></s></s></s></s></s>,.</s></s></s>',\n",
       " '</s></s>i C C for forans and for for for for for, for respectively and.:,. per per for,,.., and,,,,,,,,,,,arer,,,,,,,,,,,,,,,,,,,,,',\n",
       " '<s></s></s></s></s></s></s> more</s> more toem</s></s> of</s></s></s></s> cities</s></s></s></s></s></s></s> more league redditueem</s></s></s> more</s></s></s></s></s> cities more</s> to cities cities Noah</s> contests reddit Brooklyn Brooklyn cities Brooklyn Brooklyn lottery Brooklyn rights</s> reddit reddit reddit</s>',\n",
       " '<s>.</s>.</s>. and and of and</s> to and says with and and and and patch and to and and</s> to and part to.p- and to</s> saypp- and that will</s> support and to to say say to support and to and say and sayp out to and and and and',\n",
       " '<s></s>akel will</s>u</s></s></s> vine</s> diaper</s>avin</s>vs vine vine vine vine victory vinebat</s> versus vine Vietnam will willwill willsave will vegan victory will, will vegan</s> will vegan vegan destination will will will will will will</s> will- will vine will will versus standby standby will vine</s>',\n",
       " '<s></s>Big</s></s> change</s></s></s></s></s><s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>.</s></s></s>. media</s></s></s> social</s> change new change change change change change change change change change change change change change change change change change',\n",
       " '</s></s></s> and and</s></s></s></s></s></s></s></s></s></s>.</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> location</s></s> location</s></s></s> location</s></s> location location location location location</s></s> location</s> ingredient</s>',\n",
       " '<s></s>Quotes<s> Name<s>CNN,</s> and,,,,, and,,,,,,, United Premier Premier,,,, Premier,,, United,,,,, Premier,,, Premier Premier, Premier,,,,,,,, state,,,,, Premier,',\n",
       " '<s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> media</s></s></s></s></s></s></s></s></s> Prev</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s> the</s></s></s></s></s> local</s>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(predictions['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesisenv-local]",
   "language": "python",
   "name": "conda-env-thesisenv-local-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
